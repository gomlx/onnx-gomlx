{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f5cd05-8e1b-4873-8220-7cd7577da125",
   "metadata": {},
   "source": [
    "# Converting ONNX models to GoMLX\n",
    "\n",
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cdd74c0-e5af-45d6-93d8-7453b1a590f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**GoNB** version [v0.10.6](https://github.com/janpfeifer/gonb/releases/tag/v0.10.6) / Commit: [0e5f587a077810d058202b76a127651a02bd4382](https://github.com/janpfeifer/gonb/tree/0e5f587a077810d058202b76a127651a02bd4382)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Added replace rule for module \"github.com/gomlx/gomlx\" to local directory \"/home/janpf/Projects/gomlx\".\n",
      "\t- Added replace rule for module \"github.com/janpfeifer/gonb\" to local directory \"/home/janpf/Projects/gonb\".\n",
      "\t- Added replace rule for module \"github.com/gomlx/onnx-gomlx\" to local directory \"/home/janpf/Projects/onnx-gomlx\".\n"
     ]
    }
   ],
   "source": [
    "%version\n",
    "!*rm -f go.work && go work init\n",
    "!*go work use . \"${HOME}/Projects/gonb\" \"${HOME}/Projects/gomlx\" \"${HOME}/Projects/onnx-gomlx\"\n",
    "%goworkfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "adeca919-f2ed-4d8b-93fb-6978f94de2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "\t\"fmt\"\n",
    "\t\"os\"\n",
    "\n",
    "\t\"github.com/gogo/protobuf/proto\"\n",
    "\t\"github.com/janpfeifer/must\"\n",
    "\n",
    "\t\"github.com/gomlx/gomlx/backends\"\n",
    "    . \"github.com/gomlx/gomlx/graph\"\n",
    "\t\"github.com/gomlx/gomlx/ml/context\"\n",
    "\t\"github.com/gomlx/gomlx/ml/data\"\n",
    "\t\"github.com/gomlx/gomlx/types\"\n",
    "\t\"github.com/gomlx/gopjrt/dtypes\"\n",
    "    \"github.com/gomlx/onnx-gomlx/onnx\"\n",
    "\t\"github.com/pkg/errors\"\n",
    "\n",
    "\t_ \"github.com/gomlx/gomlx/backends/xla\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    _ = Add\n",
    "    backend = backends.New()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273d236-cb0d-4d92-a0f0-e9b9d6f6e156",
   "metadata": {},
   "source": [
    "## Linear Model\n",
    "\n",
    "The `linear_regression.onnx` was created manually using python (see accompanying `onnx-py.ipynb` notebook):\n",
    "\n",
    "```python\n",
    "feature_dim = 5\n",
    "X = make_tensor_value_info('X', TensorProto.FLOAT, [\"batch_size\", feature_dim])\n",
    "Y = make_tensor_value_info('Y', TensorProto.FLOAT, [\"batch_size\"])\n",
    "A_initializer = onnx.helper.make_tensor('A', TensorProto.FLOAT, [feature_dim], [100.0, 10.0, 1.0, 0.1, 0.01])\n",
    "B_initializer = onnx.helper.make_tensor('B', TensorProto.FLOAT, [], [7000.0])\n",
    "node1 = make_node('MatMul', ['X', 'A'], ['XA'], 'XA')\n",
    "node2 = make_node('Add', ['XA', 'B'], ['Y'], 'Y')\n",
    "graph = make_graph([node1, node2], 'lr', [X], [Y], initializer=[A_initializer, B_initializer])\n",
    "onnx_model = make_model(graph)\n",
    "check_model(onnx_model)\n",
    "with open(\"linear_regression.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c2fa3d-78e6-4283-be3d-1ccaa0ddffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Model:\n",
      "\t# inputs:\t1\n",
      "\t\t[#0] X: (Float32) [batch_size, 5]\n",
      "\t# outputs:\t1\n",
      "\t\t[#0] Y: (Float32) [batch_size]\n",
      "\t# nodes:\t2\n",
      "\t# tensors (variables):\t2\n",
      "\t# sparse tensors (variables):\t0\n",
      "\tOp types:\t[]string{\"Add\", \"MatMul\"}\n",
      "\tIR Version:\t10\n",
      "\tOperator Sets:\t[v21]\n",
      "\n",
      "2 tensors (variables):\n",
      "\t\"A\": (Float32)[5]\n",
      "\t\"B\": (Float32)\n",
      "0 sparse tensors (variables)\n",
      "\n",
      "Model Graph \"lr\":\n",
      "\"XA\":\t[MatMul]\n",
      "\tInputs: [\"X\" \"A\"]\n",
      "\tOutputs: [\"XA\"]\n",
      "\"Y\":\t[Add]\n",
      "\tInputs: [\"XA\" \"B\"]\n",
      "\tOutputs: [\"Y\"]\n",
      "\n",
      "Variables loaded from \"/home/janpf/work/onnx/linear_regression.onnx\":\n",
      "\t- /ONNX/A: (Float32)[5]: []float32{100, 10, 1, 0.1, 0.01}\n",
      "\t- /ONNX/B: float32(7000)\n",
      "\n",
      "Example invocation:\n",
      "\tX*A+B=(Float32)[2]: []float32{7123.45, 7679}\n"
     ]
    }
   ],
   "source": [
    "var modelPath = data.ReplaceTildeInDir(\"~/work/onnx/linear_regression.onnx\") // all-MiniLM-L6-v2\n",
    "\n",
    "%%\n",
    "// Read and print the onnx model:\n",
    "model := must.M1(onnx.ReadFile(modelPath))\n",
    "fmt.Printf(\"%s\\n\", model)\n",
    "must.M(model.PrintVariables(os.Stdout))\n",
    "fmt.Println()\n",
    "must.M(model.PrintGraph(os.Stdout))\n",
    "fmt.Println()\n",
    "\n",
    "// Convert ONNX variables to GoMLX context (which stores variables):\n",
    "ctx := context.New()\n",
    "must.M(model.VariablesToContext(ctx))\n",
    "fmt.Printf(\"Variables loaded from %q:\\n\", modelPath)\n",
    "for v := range ctx.IterVariables() {\n",
    "    fmt.Printf(\"\\t- %s: %s\\n\", v.ScopeAndName(), v.Value().GoStr())\n",
    "}\n",
    "fmt.Println()\n",
    "\n",
    "// Execute it with GoMLX/XLA:\n",
    "gomlxFn := func(ctx *context.Context, x *Node) *Node {\n",
    "    return model.CallGraph(ctx, x.Graph(), map[string]*Node{\"X\": x})[0]\n",
    "}\n",
    "x := [][]float32{{1, 2, 3, 4, 5}, {6, 7, 8, 9, 10}}\n",
    "fmt.Println(\"Example invocation:\")\n",
    "fmt.Printf(\"\\tX*A+B=%v\\n\", context.ExecOnce(backend, ctx, gomlxFn, x).GoStr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19434069-043d-4819-9cc7-1506ad31a143",
   "metadata": {},
   "source": [
    "## [Sentence Enconding all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "\n",
    "From the downloaded file `model.onnx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2240c215-8169-4e17-a64e-2628c2bbdca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "func miniLM(verbose bool, targetOutputs ...string) []*tensors.Tensor {\n",
    "    modelPath = data.ReplaceTildeInDir(\"~/work/onnx/model.onnx\") // all-MiniLM-L6-v2\n",
    "    // Read and print the onnx model:\n",
    "    model := must.M1(onnx.ReadFile(modelPath))\n",
    "    if verbose {\n",
    "        fmt.Printf(\"%s\\n\", model)\n",
    "    }\n",
    "        \n",
    "    // Create a file for debugging with detailed graph.\n",
    "    if verbose {\n",
    "        debugFile := must.M1(os.Create(\"graph.txt\"))\n",
    "        must.M(model.PrintVariables(debugFile))\n",
    "        fmt.Println()\n",
    "        must.M(model.PrintGraph(debugFile))\n",
    "        fmt.Println()\n",
    "        must.M(debugFile.Close())\n",
    "\n",
    "        dotFile := must.M1(os.Create(\"graph.dot\"))\n",
    "        must.M(model.PrintGraphviz(dotFile))\n",
    "        must.M(dotFile.Close())\n",
    "    }\n",
    "    \n",
    "    // Convert ONNX variables to GoMLX context (which stores variables):\n",
    "    ctx := context.New()\n",
    "    must.M(model.VariablesToContext(ctx))\n",
    "    \n",
    "    // Execute it with GoMLX/XLA:\n",
    "    sentences := []string{\n",
    "        \"This is an example sentence\", \n",
    "        \"Each sentence is converted\"}\n",
    "\n",
    "    // Encoding to tokens done in Python and pasted here.\n",
    "    inputIDs := [][]int64{\n",
    "        {101, 2023, 2003, 2019, 2742, 6251,  102},\n",
    "        { 101, 2169, 6251, 2003, 4991,  102,    0}}\n",
    "    tokenTypeIDs := [][]int64{\n",
    "        {0, 0, 0, 0, 0, 0, 0},\n",
    "        {0, 0, 0, 0, 0, 0, 0}}\n",
    "    attentionMask := [][]int64{\n",
    "        {1, 1, 1, 1, 1, 1, 1},\n",
    "        {1, 1, 1, 1, 1, 1, 0}}\n",
    "    if verbose {\n",
    "        fmt.Println(\"Example invocation:\")\n",
    "        fmt.Printf(\"\\tall-MiniLM-L6-v2(%#v)=\\n\", sentences)\n",
    "    }\n",
    "    var embeddings []*tensors.Tensor\n",
    "    err := exceptions.TryCatch[error](func() {\n",
    "        embeddings = context.ExecOnceN(\n",
    "            backend, ctx, func (ctx *context.Context, inputs []*Node) []*Node {\n",
    "                return model.CallGraph(ctx, inputs[0].Graph(), map[string]*Node{\n",
    "                \"input_ids\": inputs[0],\n",
    "                \"attention_mask\": inputs[1],\n",
    "                \"token_type_ids\": inputs[2]}, targetOutputs...)\n",
    "            }, inputIDs, attentionMask, tokenTypeIDs)\n",
    "    })\n",
    "    must.M(err)\n",
    "    return embeddings\n",
    "}\n",
    "\n",
    "func p(target string) {\n",
    "    output := miniLM(false, target)[0]\n",
    "    fmt.Printf(\"\\n%s:\\n\", target)\n",
    "    fmt.Printf(\"%s\\n\", output)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b62fcf64-49b1-4f2b-b0f1-cb77dd5838d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set: GOMLX_BACKEND=\"xla:cuda\"\n",
      "\n",
      "/embeddings/Add_1_output_0:\n",
      "[2][7][384]float32{\n",
      " {{-0.0886, -0.0368, 0.0180, ..., 0.0261, 0.0912, -0.0152},\n",
      "  {-0.0200, -0.0014, -0.0177, ..., 0.0204, 0.0522, 0.1991},\n",
      "  {-0.0196, -0.0336, -0.0319, ..., 0.0203, 0.0709, 0.0644},\n",
      "  ...,\n",
      "  {-0.0253, 0.0408, 0.0125, ..., -0.0270, 0.0377, 0.1133},\n",
      "  {-0.0140, -0.0275, 0.0796, ..., -0.0748, 0.0774, -0.0657},\n",
      "  {0.0318, -0.0032, -0.0210, ..., 0.0387, 0.0191, -0.0059}},\n",
      " {{-0.0886, -0.0368, 0.0180, ..., 0.0261, 0.0912, -0.0152},\n",
      "  {0.0304, 0.0531, -0.0238, ..., -0.1011, 0.0218, 0.0473},\n",
      "  {-0.0027, -0.0508, 0.0805, ..., -0.0777, 0.0881, -0.0560},\n",
      "  ...,\n",
      "  {0.0928, 0.0165, -0.0976, ..., 0.0449, 0.0390, -0.0182},\n",
      "  {0.0231, 0.0090, -0.0213, ..., 0.0232, 0.0191, -0.0066},\n",
      "  {-0.0213, 0.0019, 0.0043, ..., 0.0561, 0.0170, 0.0256}}}\n"
     ]
    }
   ],
   "source": [
    "%env GOMLX_BACKEND=\"xla:cuda\"\n",
    "%%\n",
    "// p(\"/embeddings/Slice_output_0\")\n",
    "// p(\"/embeddings/position_embeddings/Gather_output_0\")\n",
    "// p(\"token_type_ids\")\n",
    "// p(\"embeddings.token_type_embeddings.weight\")\n",
    "// p(\"/embeddings/token_type_embeddings/Gather_output_0\")\n",
    "// p(\"/embeddings/Add_output_0\")\n",
    "p(\"/embeddings/Add_1_output_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "417dd1fb-c111-4280-9744-bbadeff477ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Shape_output_0: (Int64)[2]\n",
      "/Constant_output_0: (Int64)\n",
      "/Gather_output_0: (Int64)\n",
      "onnx::Slice_110: (Int64)[1 512]\n",
      "/embeddings/Constant_output_0: (Int64)[1]\n",
      "/embeddings/Constant_1_output_0: (Int64)[1]\n",
      "/embeddings/Constant_2_output_0: (Int64)[1]\n",
      "/embeddings/Unsqueeze_output_0: (Int64)[1]\n",
      "/embeddings/Constant_3_output_0: (Int64)[1]\n",
      "/embeddings/Slice_output_0: (Int64)[1 7]\n",
      "/embeddings/word_embeddings/Gather_output_0: (Float32)[2 7 384]\n",
      "/embeddings/token_type_embeddings/Gather_output_0: (Float32)[2 7 384]\n",
      "/embeddings/Add_output_0: (Float32)[2 7 384]\n",
      "/embeddings/position_embeddings/Gather_output_0: (Float32)[1 7 384]\n",
      "/embeddings/Add_1_output_0: (Float32)[2 7 384]\n",
      "/embeddings/LayerNorm/ReduceMean_output_0: (Float32)[2 7 1]\n",
      "/embeddings/LayerNorm/Sub_output_0: (Float32)[2 7 384]\n",
      "/embeddings/LayerNorm/Constant_output_0: (Float32)\n",
      "/embeddings/LayerNorm/Pow_output_0: (Float32)[2 7 384]\n",
      "/embeddings/LayerNorm/ReduceMean_1_output_0: (Float32)[2 7 1]\n",
      "/embeddings/LayerNorm/Constant_1_output_0: (Float32)\n",
      "/embeddings/LayerNorm/Add_output_0: (Float32)[2 7 1]\n",
      "/embeddings/LayerNorm/Sqrt_output_0: (Float32)[2 7 1]\n",
      "/embeddings/LayerNorm/Div_output_0: (Float32)[2 7 384]\n",
      "/embeddings/LayerNorm/Mul_output_0: (Float32)[2 7 384]\n",
      "/embeddings/LayerNorm/Add_1_output_0: (Float32)[2 7 384]\n",
      "/Shape_1_output_0: (Int64)[2]\n",
      "/Constant_1_output_0: (Int64)\n",
      "/Gather_1_output_0: (Int64)\n",
      "/Shape_2_output_0: (Int64)[2]\n",
      "/Constant_2_output_0: (Int64)\n",
      "/Gather_2_output_0: (Int64)\n",
      "/Constant_3_output_0: (Int64)[1]\n",
      "/Unsqueeze_output_0: (Int64)[2 1 7]\n",
      "/Constant_4_output_0: (Int64)[1]\n",
      "/Unsqueeze_1_output_0: (Int64)[2 1 1 7]\n",
      "/Constant_5_output_0: (Int64)[1]\n",
      "/Unsqueeze_2_output_0: (Int64)[1]\n",
      "/Constant_6_output_0: (Int64)[1]\n",
      "/Constant_7_output_0: (Int64)[1]\n",
      "/Unsqueeze_3_output_0: (Int64)[1]\n",
      "/Constant_8_output_0: (Int64)[1]\n",
      "/Unsqueeze_4_output_0: (Int64)[1]\n",
      "/Concat_output_0: (Int64)[4]\n",
      "/Constant_9_output_0: (Int64)[1]\n",
      "/Reshape_output_0: (Int64)[4]\n",
      "/Shape_3_output_0: (Int64)[1]\n",
      "/ConstantOfShape_output_0: (Int64)[4]\n",
      "/Constant_10_output_0: (Int64)\n",
      "/Mul_output_0: (Int64)[4]\n",
      "/Equal_output_0: (Bool)[4]\n",
      "/Where_output_0: (Int64)[4]\n",
      "/Expand_output_0: (Int64)[2 1 7 7]\n",
      "/Cast_output_0: (Float32)[2 1 7 7]\n",
      "/Constant_11_output_0: (Float32)\n",
      "/Sub_output_0: (Float32)[2 1 7 7]\n",
      "/Cast_1_output_0: (Bool)[2 1 7 7]\n",
      "/Cast_2_output_0: (Bool)[2 1 7 7]\n",
      "/Constant_12_output_0: (Float32)\n",
      "/Where_1_output_0: (Float32)[2 1 7 7]\n",
      "/encoder/layer.0/attention/self/Shape_output_0: (Int64)[3]\n",
      "/encoder/layer.0/attention/self/Constant_output_0: (Int64)\n",
      "/encoder/layer.0/attention/self/Gather_output_0: (Int64)\n",
      "/encoder/layer.0/attention/self/Shape_1_output_0: (Int64)[3]\n",
      "/encoder/layer.0/attention/self/Constant_1_output_0: (Int64)\n",
      "/encoder/layer.0/attention/self/Gather_1_output_0: (Int64)\n",
      "/encoder/layer.0/attention/self/query/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/attention/self/query/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/attention/self/Shape_2_output_0: (Int64)[3]\n",
      "/encoder/layer.0/attention/self/Constant_2_output_0: (Int64)\n",
      "/encoder/layer.0/attention/self/Gather_2_output_0: (Int64)\n",
      "/encoder/layer.0/attention/self/Shape_3_output_0: (Int64)[3]\n",
      "/encoder/layer.0/attention/self/Constant_3_output_0: (Int64)\n",
      "/encoder/layer.0/attention/self/Gather_3_output_0: (Int64)\n",
      "onnx::Unsqueeze_189: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Unsqueeze_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_191: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Unsqueeze_1_output_0: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Constant_4_output_0: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Constant_5_output_0: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Concat_output_0: (Int64)[4]\n",
      "/encoder/layer.0/attention/self/Reshape_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.0/attention/self/Transpose_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.0/attention/self/key/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/attention/self/key/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/attention/self/Shape_4_output_0: (Int64)[3]\n",
      "/encoder/layer.0/attention/self/Constant_6_output_0: (Int64)\n",
      "/encoder/layer.0/attention/self/Gather_4_output_0: (Int64)\n",
      "/encoder/layer.0/attention/self/Shape_5_output_0: (Int64)[3]\n",
      "/encoder/layer.0/attention/self/Constant_7_output_0: (Int64)\n",
      "/encoder/layer.0/attention/self/Gather_5_output_0: (Int64)\n",
      "onnx::Unsqueeze_209: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Unsqueeze_2_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_211: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Unsqueeze_3_output_0: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Constant_8_output_0: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Constant_9_output_0: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Concat_1_output_0: (Int64)[4]\n",
      "/encoder/layer.0/attention/self/Reshape_1_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.0/attention/self/value/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/attention/self/value/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/attention/self/Shape_6_output_0: (Int64)[3]\n",
      "/encoder/layer.0/attention/self/Constant_10_output_0: (Int64)\n",
      "/encoder/layer.0/attention/self/Gather_6_output_0: (Int64)\n",
      "/encoder/layer.0/attention/self/Shape_7_output_0: (Int64)[3]\n",
      "/encoder/layer.0/attention/self/Constant_11_output_0: (Int64)\n",
      "/encoder/layer.0/attention/self/Gather_7_output_0: (Int64)\n",
      "onnx::Unsqueeze_228: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Unsqueeze_4_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_230: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Unsqueeze_5_output_0: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Constant_12_output_0: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Constant_13_output_0: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Concat_2_output_0: (Int64)[4]\n",
      "/encoder/layer.0/attention/self/Reshape_2_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.0/attention/self/Transpose_1_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.0/attention/self/Shape_8_output_0: (Int64)[4]\n",
      "/encoder/layer.0/attention/self/Constant_14_output_0: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Constant_15_output_0: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Slice_output_0: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Cast_output_0: (Float32)[1]\n",
      "/encoder/layer.0/attention/self/Sqrt_output_0: (Float32)[1]\n",
      "/encoder/layer.0/attention/self/Constant_16_output_0: (Float32)[1]\n",
      "/encoder/layer.0/attention/self/Div_output_0: (Float32)[1]\n",
      "/encoder/layer.0/attention/self/Cast_1_output_0: (Float32)[1]\n",
      "/encoder/layer.0/attention/self/Transpose_2_output_0: (Float32)[2 12 32 7]\n",
      "/encoder/layer.0/attention/self/Sqrt_1_output_0: (Float32)[1]\n",
      "/encoder/layer.0/attention/self/Mul_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.0/attention/self/Sqrt_2_output_0: (Float32)[1]\n",
      "/encoder/layer.0/attention/self/Mul_1_output_0: (Float32)[2 12 32 7]\n",
      "/encoder/layer.0/attention/self/MatMul_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.0/attention/self/Add_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.0/attention/self/Softmax_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.0/attention/self/MatMul_1_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.0/attention/self/Transpose_3_output_0: (Float32)[2 7 12 32]\n",
      "onnx::Unsqueeze_259: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Unsqueeze_6_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_261: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Unsqueeze_7_output_0: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Constant_17_output_0: (Int64)[1]\n",
      "/encoder/layer.0/attention/self/Concat_3_output_0: (Int64)[3]\n",
      "/encoder/layer.0/attention/self/Reshape_3_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/attention/output/dense/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/attention/output/dense/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/attention/output/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.0/attention/output/LayerNorm/Sub_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/attention/output/LayerNorm/Constant_output_0: (Float32)\n",
      "/encoder/layer.0/attention/output/LayerNorm/Pow_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.0/attention/output/LayerNorm/Add_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.0/attention/output/LayerNorm/Div_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/attention/output/LayerNorm/Mul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/intermediate/dense/MatMul_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.0/intermediate/dense/Add_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0: (Float32)\n",
      "/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0: (Float32)\n",
      "/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.0/output/dense/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/output/dense/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/output/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/output/LayerNorm/ReduceMean_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.0/output/LayerNorm/Sub_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/output/LayerNorm/Constant_output_0: (Float32)\n",
      "/encoder/layer.0/output/LayerNorm/Pow_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.0/output/LayerNorm/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.0/output/LayerNorm/Add_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.0/output/LayerNorm/Sqrt_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.0/output/LayerNorm/Div_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/output/LayerNorm/Mul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.0/output/LayerNorm/Add_1_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/self/Shape_output_0: (Int64)[3]\n",
      "/encoder/layer.1/attention/self/Constant_output_0: (Int64)\n",
      "/encoder/layer.1/attention/self/Gather_output_0: (Int64)\n",
      "/encoder/layer.1/attention/self/Shape_1_output_0: (Int64)[3]\n",
      "/encoder/layer.1/attention/self/Constant_1_output_0: (Int64)\n",
      "/encoder/layer.1/attention/self/Gather_1_output_0: (Int64)\n",
      "/encoder/layer.1/attention/self/query/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/self/query/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/self/Shape_2_output_0: (Int64)[3]\n",
      "/encoder/layer.1/attention/self/Constant_2_output_0: (Int64)\n",
      "/encoder/layer.1/attention/self/Gather_2_output_0: (Int64)\n",
      "/encoder/layer.1/attention/self/Shape_3_output_0: (Int64)[3]\n",
      "/encoder/layer.1/attention/self/Constant_3_output_0: (Int64)\n",
      "/encoder/layer.1/attention/self/Gather_3_output_0: (Int64)\n",
      "onnx::Unsqueeze_323: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Unsqueeze_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_325: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Unsqueeze_1_output_0: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Constant_4_output_0: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Constant_5_output_0: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Concat_output_0: (Int64)[4]\n",
      "/encoder/layer.1/attention/self/Reshape_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.1/attention/self/Transpose_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.1/attention/self/key/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/self/key/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/self/Shape_4_output_0: (Int64)[3]\n",
      "/encoder/layer.1/attention/self/Constant_6_output_0: (Int64)\n",
      "/encoder/layer.1/attention/self/Gather_4_output_0: (Int64)\n",
      "/encoder/layer.1/attention/self/Shape_5_output_0: (Int64)[3]\n",
      "/encoder/layer.1/attention/self/Constant_7_output_0: (Int64)\n",
      "/encoder/layer.1/attention/self/Gather_5_output_0: (Int64)\n",
      "onnx::Unsqueeze_343: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Unsqueeze_2_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_345: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Unsqueeze_3_output_0: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Constant_8_output_0: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Constant_9_output_0: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Concat_1_output_0: (Int64)[4]\n",
      "/encoder/layer.1/attention/self/Reshape_1_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.1/attention/self/value/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/self/value/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/self/Shape_6_output_0: (Int64)[3]\n",
      "/encoder/layer.1/attention/self/Constant_10_output_0: (Int64)\n",
      "/encoder/layer.1/attention/self/Gather_6_output_0: (Int64)\n",
      "/encoder/layer.1/attention/self/Shape_7_output_0: (Int64)[3]\n",
      "/encoder/layer.1/attention/self/Constant_11_output_0: (Int64)\n",
      "/encoder/layer.1/attention/self/Gather_7_output_0: (Int64)\n",
      "onnx::Unsqueeze_362: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Unsqueeze_4_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_364: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Unsqueeze_5_output_0: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Constant_12_output_0: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Constant_13_output_0: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Concat_2_output_0: (Int64)[4]\n",
      "/encoder/layer.1/attention/self/Reshape_2_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.1/attention/self/Transpose_1_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.1/attention/self/Shape_8_output_0: (Int64)[4]\n",
      "/encoder/layer.1/attention/self/Constant_14_output_0: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Constant_15_output_0: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Slice_output_0: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Cast_output_0: (Float32)[1]\n",
      "/encoder/layer.1/attention/self/Sqrt_output_0: (Float32)[1]\n",
      "/encoder/layer.1/attention/self/Constant_16_output_0: (Float32)[1]\n",
      "/encoder/layer.1/attention/self/Div_output_0: (Float32)[1]\n",
      "/encoder/layer.1/attention/self/Cast_1_output_0: (Float32)[1]\n",
      "/encoder/layer.1/attention/self/Transpose_2_output_0: (Float32)[2 12 32 7]\n",
      "/encoder/layer.1/attention/self/Sqrt_1_output_0: (Float32)[1]\n",
      "/encoder/layer.1/attention/self/Mul_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.1/attention/self/Sqrt_2_output_0: (Float32)[1]\n",
      "/encoder/layer.1/attention/self/Mul_1_output_0: (Float32)[2 12 32 7]\n",
      "/encoder/layer.1/attention/self/MatMul_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.1/attention/self/Add_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.1/attention/self/Softmax_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.1/attention/self/MatMul_1_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.1/attention/self/Transpose_3_output_0: (Float32)[2 7 12 32]\n",
      "onnx::Unsqueeze_392: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Unsqueeze_6_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_394: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Unsqueeze_7_output_0: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Constant_17_output_0: (Int64)[1]\n",
      "/encoder/layer.1/attention/self/Concat_3_output_0: (Int64)[3]\n",
      "/encoder/layer.1/attention/self/Reshape_3_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/output/dense/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/output/dense/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/output/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.1/attention/output/LayerNorm/Sub_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/output/LayerNorm/Constant_output_0: (Float32)\n",
      "/encoder/layer.1/attention/output/LayerNorm/Pow_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.1/attention/output/LayerNorm/Add_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.1/attention/output/LayerNorm/Div_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/output/LayerNorm/Mul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/intermediate/dense/MatMul_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.1/intermediate/dense/Add_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0: (Float32)\n",
      "/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0: (Float32)\n",
      "/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.1/output/dense/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/output/dense/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/output/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/output/LayerNorm/ReduceMean_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.1/output/LayerNorm/Sub_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/output/LayerNorm/Constant_output_0: (Float32)\n",
      "/encoder/layer.1/output/LayerNorm/Pow_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.1/output/LayerNorm/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.1/output/LayerNorm/Add_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.1/output/LayerNorm/Sqrt_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.1/output/LayerNorm/Div_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/output/LayerNorm/Mul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.1/output/LayerNorm/Add_1_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/self/Shape_output_0: (Int64)[3]\n",
      "/encoder/layer.2/attention/self/Constant_output_0: (Int64)\n",
      "/encoder/layer.2/attention/self/Gather_output_0: (Int64)\n",
      "/encoder/layer.2/attention/self/Shape_1_output_0: (Int64)[3]\n",
      "/encoder/layer.2/attention/self/Constant_1_output_0: (Int64)\n",
      "/encoder/layer.2/attention/self/Gather_1_output_0: (Int64)\n",
      "/encoder/layer.2/attention/self/query/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/self/query/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/self/Shape_2_output_0: (Int64)[3]\n",
      "/encoder/layer.2/attention/self/Constant_2_output_0: (Int64)\n",
      "/encoder/layer.2/attention/self/Gather_2_output_0: (Int64)\n",
      "/encoder/layer.2/attention/self/Shape_3_output_0: (Int64)[3]\n",
      "/encoder/layer.2/attention/self/Constant_3_output_0: (Int64)\n",
      "/encoder/layer.2/attention/self/Gather_3_output_0: (Int64)\n",
      "onnx::Unsqueeze_456: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Unsqueeze_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_458: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Unsqueeze_1_output_0: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Constant_4_output_0: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Constant_5_output_0: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Concat_output_0: (Int64)[4]\n",
      "/encoder/layer.2/attention/self/Reshape_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.2/attention/self/Transpose_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.2/attention/self/key/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/self/key/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/self/Shape_4_output_0: (Int64)[3]\n",
      "/encoder/layer.2/attention/self/Constant_6_output_0: (Int64)\n",
      "/encoder/layer.2/attention/self/Gather_4_output_0: (Int64)\n",
      "/encoder/layer.2/attention/self/Shape_5_output_0: (Int64)[3]\n",
      "/encoder/layer.2/attention/self/Constant_7_output_0: (Int64)\n",
      "/encoder/layer.2/attention/self/Gather_5_output_0: (Int64)\n",
      "onnx::Unsqueeze_476: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Unsqueeze_2_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_478: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Unsqueeze_3_output_0: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Constant_8_output_0: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Constant_9_output_0: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Concat_1_output_0: (Int64)[4]\n",
      "/encoder/layer.2/attention/self/Reshape_1_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.2/attention/self/value/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/self/value/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/self/Shape_6_output_0: (Int64)[3]\n",
      "/encoder/layer.2/attention/self/Constant_10_output_0: (Int64)\n",
      "/encoder/layer.2/attention/self/Gather_6_output_0: (Int64)\n",
      "/encoder/layer.2/attention/self/Shape_7_output_0: (Int64)[3]\n",
      "/encoder/layer.2/attention/self/Constant_11_output_0: (Int64)\n",
      "/encoder/layer.2/attention/self/Gather_7_output_0: (Int64)\n",
      "onnx::Unsqueeze_495: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Unsqueeze_4_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_497: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Unsqueeze_5_output_0: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Constant_12_output_0: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Constant_13_output_0: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Concat_2_output_0: (Int64)[4]\n",
      "/encoder/layer.2/attention/self/Reshape_2_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.2/attention/self/Transpose_1_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.2/attention/self/Shape_8_output_0: (Int64)[4]\n",
      "/encoder/layer.2/attention/self/Constant_14_output_0: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Constant_15_output_0: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Slice_output_0: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Cast_output_0: (Float32)[1]\n",
      "/encoder/layer.2/attention/self/Sqrt_output_0: (Float32)[1]\n",
      "/encoder/layer.2/attention/self/Constant_16_output_0: (Float32)[1]\n",
      "/encoder/layer.2/attention/self/Div_output_0: (Float32)[1]\n",
      "/encoder/layer.2/attention/self/Cast_1_output_0: (Float32)[1]\n",
      "/encoder/layer.2/attention/self/Transpose_2_output_0: (Float32)[2 12 32 7]\n",
      "/encoder/layer.2/attention/self/Sqrt_1_output_0: (Float32)[1]\n",
      "/encoder/layer.2/attention/self/Mul_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.2/attention/self/Sqrt_2_output_0: (Float32)[1]\n",
      "/encoder/layer.2/attention/self/Mul_1_output_0: (Float32)[2 12 32 7]\n",
      "/encoder/layer.2/attention/self/MatMul_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.2/attention/self/Add_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.2/attention/self/Softmax_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.2/attention/self/MatMul_1_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.2/attention/self/Transpose_3_output_0: (Float32)[2 7 12 32]\n",
      "onnx::Unsqueeze_525: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Unsqueeze_6_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_527: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Unsqueeze_7_output_0: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Constant_17_output_0: (Int64)[1]\n",
      "/encoder/layer.2/attention/self/Concat_3_output_0: (Int64)[3]\n",
      "/encoder/layer.2/attention/self/Reshape_3_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/output/dense/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/output/dense/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/output/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.2/attention/output/LayerNorm/Sub_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/output/LayerNorm/Constant_output_0: (Float32)\n",
      "/encoder/layer.2/attention/output/LayerNorm/Pow_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.2/attention/output/LayerNorm/Add_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.2/attention/output/LayerNorm/Div_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/output/LayerNorm/Mul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/intermediate/dense/MatMul_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.2/intermediate/dense/Add_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0: (Float32)\n",
      "/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0: (Float32)\n",
      "/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.2/output/dense/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/output/dense/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/output/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/output/LayerNorm/ReduceMean_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.2/output/LayerNorm/Sub_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/output/LayerNorm/Constant_output_0: (Float32)\n",
      "/encoder/layer.2/output/LayerNorm/Pow_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.2/output/LayerNorm/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.2/output/LayerNorm/Add_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.2/output/LayerNorm/Sqrt_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.2/output/LayerNorm/Div_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/output/LayerNorm/Mul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.2/output/LayerNorm/Add_1_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/self/Shape_output_0: (Int64)[3]\n",
      "/encoder/layer.3/attention/self/Constant_output_0: (Int64)\n",
      "/encoder/layer.3/attention/self/Gather_output_0: (Int64)\n",
      "/encoder/layer.3/attention/self/Shape_1_output_0: (Int64)[3]\n",
      "/encoder/layer.3/attention/self/Constant_1_output_0: (Int64)\n",
      "/encoder/layer.3/attention/self/Gather_1_output_0: (Int64)\n",
      "/encoder/layer.3/attention/self/query/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/self/query/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/self/Shape_2_output_0: (Int64)[3]\n",
      "/encoder/layer.3/attention/self/Constant_2_output_0: (Int64)\n",
      "/encoder/layer.3/attention/self/Gather_2_output_0: (Int64)\n",
      "/encoder/layer.3/attention/self/Shape_3_output_0: (Int64)[3]\n",
      "/encoder/layer.3/attention/self/Constant_3_output_0: (Int64)\n",
      "/encoder/layer.3/attention/self/Gather_3_output_0: (Int64)\n",
      "onnx::Unsqueeze_589: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Unsqueeze_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_591: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Unsqueeze_1_output_0: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Constant_4_output_0: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Constant_5_output_0: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Concat_output_0: (Int64)[4]\n",
      "/encoder/layer.3/attention/self/Reshape_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.3/attention/self/Transpose_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.3/attention/self/key/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/self/key/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/self/Shape_4_output_0: (Int64)[3]\n",
      "/encoder/layer.3/attention/self/Constant_6_output_0: (Int64)\n",
      "/encoder/layer.3/attention/self/Gather_4_output_0: (Int64)\n",
      "/encoder/layer.3/attention/self/Shape_5_output_0: (Int64)[3]\n",
      "/encoder/layer.3/attention/self/Constant_7_output_0: (Int64)\n",
      "/encoder/layer.3/attention/self/Gather_5_output_0: (Int64)\n",
      "onnx::Unsqueeze_609: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Unsqueeze_2_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_611: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Unsqueeze_3_output_0: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Constant_8_output_0: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Constant_9_output_0: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Concat_1_output_0: (Int64)[4]\n",
      "/encoder/layer.3/attention/self/Reshape_1_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.3/attention/self/value/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/self/value/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/self/Shape_6_output_0: (Int64)[3]\n",
      "/encoder/layer.3/attention/self/Constant_10_output_0: (Int64)\n",
      "/encoder/layer.3/attention/self/Gather_6_output_0: (Int64)\n",
      "/encoder/layer.3/attention/self/Shape_7_output_0: (Int64)[3]\n",
      "/encoder/layer.3/attention/self/Constant_11_output_0: (Int64)\n",
      "/encoder/layer.3/attention/self/Gather_7_output_0: (Int64)\n",
      "onnx::Unsqueeze_628: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Unsqueeze_4_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_630: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Unsqueeze_5_output_0: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Constant_12_output_0: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Constant_13_output_0: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Concat_2_output_0: (Int64)[4]\n",
      "/encoder/layer.3/attention/self/Reshape_2_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.3/attention/self/Transpose_1_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.3/attention/self/Shape_8_output_0: (Int64)[4]\n",
      "/encoder/layer.3/attention/self/Constant_14_output_0: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Constant_15_output_0: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Slice_output_0: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Cast_output_0: (Float32)[1]\n",
      "/encoder/layer.3/attention/self/Sqrt_output_0: (Float32)[1]\n",
      "/encoder/layer.3/attention/self/Constant_16_output_0: (Float32)[1]\n",
      "/encoder/layer.3/attention/self/Div_output_0: (Float32)[1]\n",
      "/encoder/layer.3/attention/self/Cast_1_output_0: (Float32)[1]\n",
      "/encoder/layer.3/attention/self/Transpose_2_output_0: (Float32)[2 12 32 7]\n",
      "/encoder/layer.3/attention/self/Sqrt_1_output_0: (Float32)[1]\n",
      "/encoder/layer.3/attention/self/Mul_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.3/attention/self/Sqrt_2_output_0: (Float32)[1]\n",
      "/encoder/layer.3/attention/self/Mul_1_output_0: (Float32)[2 12 32 7]\n",
      "/encoder/layer.3/attention/self/MatMul_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.3/attention/self/Add_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.3/attention/self/Softmax_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.3/attention/self/MatMul_1_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.3/attention/self/Transpose_3_output_0: (Float32)[2 7 12 32]\n",
      "onnx::Unsqueeze_658: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Unsqueeze_6_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_660: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Unsqueeze_7_output_0: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Constant_17_output_0: (Int64)[1]\n",
      "/encoder/layer.3/attention/self/Concat_3_output_0: (Int64)[3]\n",
      "/encoder/layer.3/attention/self/Reshape_3_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/output/dense/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/output/dense/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/output/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.3/attention/output/LayerNorm/Sub_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/output/LayerNorm/Constant_output_0: (Float32)\n",
      "/encoder/layer.3/attention/output/LayerNorm/Pow_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.3/attention/output/LayerNorm/Add_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.3/attention/output/LayerNorm/Div_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/output/LayerNorm/Mul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/intermediate/dense/MatMul_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.3/intermediate/dense/Add_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0: (Float32)\n",
      "/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0: (Float32)\n",
      "/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.3/output/dense/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/output/dense/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/output/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/output/LayerNorm/ReduceMean_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.3/output/LayerNorm/Sub_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/output/LayerNorm/Constant_output_0: (Float32)\n",
      "/encoder/layer.3/output/LayerNorm/Pow_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.3/output/LayerNorm/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.3/output/LayerNorm/Add_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.3/output/LayerNorm/Sqrt_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.3/output/LayerNorm/Div_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/output/LayerNorm/Mul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.3/output/LayerNorm/Add_1_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/self/Shape_output_0: (Int64)[3]\n",
      "/encoder/layer.4/attention/self/Constant_output_0: (Int64)\n",
      "/encoder/layer.4/attention/self/Gather_output_0: (Int64)\n",
      "/encoder/layer.4/attention/self/Shape_1_output_0: (Int64)[3]\n",
      "/encoder/layer.4/attention/self/Constant_1_output_0: (Int64)\n",
      "/encoder/layer.4/attention/self/Gather_1_output_0: (Int64)\n",
      "/encoder/layer.4/attention/self/query/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/self/query/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/self/Shape_2_output_0: (Int64)[3]\n",
      "/encoder/layer.4/attention/self/Constant_2_output_0: (Int64)\n",
      "/encoder/layer.4/attention/self/Gather_2_output_0: (Int64)\n",
      "/encoder/layer.4/attention/self/Shape_3_output_0: (Int64)[3]\n",
      "/encoder/layer.4/attention/self/Constant_3_output_0: (Int64)\n",
      "/encoder/layer.4/attention/self/Gather_3_output_0: (Int64)\n",
      "onnx::Unsqueeze_722: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Unsqueeze_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_724: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Unsqueeze_1_output_0: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Constant_4_output_0: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Constant_5_output_0: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Concat_output_0: (Int64)[4]\n",
      "/encoder/layer.4/attention/self/Reshape_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.4/attention/self/Transpose_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.4/attention/self/key/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/self/key/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/self/Shape_4_output_0: (Int64)[3]\n",
      "/encoder/layer.4/attention/self/Constant_6_output_0: (Int64)\n",
      "/encoder/layer.4/attention/self/Gather_4_output_0: (Int64)\n",
      "/encoder/layer.4/attention/self/Shape_5_output_0: (Int64)[3]\n",
      "/encoder/layer.4/attention/self/Constant_7_output_0: (Int64)\n",
      "/encoder/layer.4/attention/self/Gather_5_output_0: (Int64)\n",
      "onnx::Unsqueeze_742: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Unsqueeze_2_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_744: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Unsqueeze_3_output_0: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Constant_8_output_0: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Constant_9_output_0: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Concat_1_output_0: (Int64)[4]\n",
      "/encoder/layer.4/attention/self/Reshape_1_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.4/attention/self/value/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/self/value/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/self/Shape_6_output_0: (Int64)[3]\n",
      "/encoder/layer.4/attention/self/Constant_10_output_0: (Int64)\n",
      "/encoder/layer.4/attention/self/Gather_6_output_0: (Int64)\n",
      "/encoder/layer.4/attention/self/Shape_7_output_0: (Int64)[3]\n",
      "/encoder/layer.4/attention/self/Constant_11_output_0: (Int64)\n",
      "/encoder/layer.4/attention/self/Gather_7_output_0: (Int64)\n",
      "onnx::Unsqueeze_761: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Unsqueeze_4_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_763: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Unsqueeze_5_output_0: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Constant_12_output_0: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Constant_13_output_0: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Concat_2_output_0: (Int64)[4]\n",
      "/encoder/layer.4/attention/self/Reshape_2_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.4/attention/self/Transpose_1_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.4/attention/self/Shape_8_output_0: (Int64)[4]\n",
      "/encoder/layer.4/attention/self/Constant_14_output_0: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Constant_15_output_0: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Slice_output_0: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Cast_output_0: (Float32)[1]\n",
      "/encoder/layer.4/attention/self/Sqrt_output_0: (Float32)[1]\n",
      "/encoder/layer.4/attention/self/Constant_16_output_0: (Float32)[1]\n",
      "/encoder/layer.4/attention/self/Div_output_0: (Float32)[1]\n",
      "/encoder/layer.4/attention/self/Cast_1_output_0: (Float32)[1]\n",
      "/encoder/layer.4/attention/self/Transpose_2_output_0: (Float32)[2 12 32 7]\n",
      "/encoder/layer.4/attention/self/Sqrt_1_output_0: (Float32)[1]\n",
      "/encoder/layer.4/attention/self/Mul_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.4/attention/self/Sqrt_2_output_0: (Float32)[1]\n",
      "/encoder/layer.4/attention/self/Mul_1_output_0: (Float32)[2 12 32 7]\n",
      "/encoder/layer.4/attention/self/MatMul_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.4/attention/self/Add_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.4/attention/self/Softmax_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.4/attention/self/MatMul_1_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.4/attention/self/Transpose_3_output_0: (Float32)[2 7 12 32]\n",
      "onnx::Unsqueeze_791: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Unsqueeze_6_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_793: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Unsqueeze_7_output_0: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Constant_17_output_0: (Int64)[1]\n",
      "/encoder/layer.4/attention/self/Concat_3_output_0: (Int64)[3]\n",
      "/encoder/layer.4/attention/self/Reshape_3_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/output/dense/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/output/dense/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/output/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.4/attention/output/LayerNorm/Sub_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/output/LayerNorm/Constant_output_0: (Float32)\n",
      "/encoder/layer.4/attention/output/LayerNorm/Pow_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.4/attention/output/LayerNorm/Add_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.4/attention/output/LayerNorm/Div_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/output/LayerNorm/Mul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/intermediate/dense/MatMul_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.4/intermediate/dense/Add_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0: (Float32)\n",
      "/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0: (Float32)\n",
      "/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.4/output/dense/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/output/dense/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/output/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/output/LayerNorm/ReduceMean_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.4/output/LayerNorm/Sub_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/output/LayerNorm/Constant_output_0: (Float32)\n",
      "/encoder/layer.4/output/LayerNorm/Pow_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.4/output/LayerNorm/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.4/output/LayerNorm/Add_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.4/output/LayerNorm/Sqrt_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.4/output/LayerNorm/Div_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/output/LayerNorm/Mul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.4/output/LayerNorm/Add_1_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/self/Shape_output_0: (Int64)[3]\n",
      "/encoder/layer.5/attention/self/Constant_output_0: (Int64)\n",
      "/encoder/layer.5/attention/self/Gather_output_0: (Int64)\n",
      "/encoder/layer.5/attention/self/Shape_1_output_0: (Int64)[3]\n",
      "/encoder/layer.5/attention/self/Constant_1_output_0: (Int64)\n",
      "/encoder/layer.5/attention/self/Gather_1_output_0: (Int64)\n",
      "/encoder/layer.5/attention/self/query/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/self/query/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/self/Shape_2_output_0: (Int64)[3]\n",
      "/encoder/layer.5/attention/self/Constant_2_output_0: (Int64)\n",
      "/encoder/layer.5/attention/self/Gather_2_output_0: (Int64)\n",
      "/encoder/layer.5/attention/self/Shape_3_output_0: (Int64)[3]\n",
      "/encoder/layer.5/attention/self/Constant_3_output_0: (Int64)\n",
      "/encoder/layer.5/attention/self/Gather_3_output_0: (Int64)\n",
      "onnx::Unsqueeze_855: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Unsqueeze_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_857: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Unsqueeze_1_output_0: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Constant_4_output_0: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Constant_5_output_0: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Concat_output_0: (Int64)[4]\n",
      "/encoder/layer.5/attention/self/Reshape_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.5/attention/self/Transpose_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.5/attention/self/key/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/self/key/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/self/Shape_4_output_0: (Int64)[3]\n",
      "/encoder/layer.5/attention/self/Constant_6_output_0: (Int64)\n",
      "/encoder/layer.5/attention/self/Gather_4_output_0: (Int64)\n",
      "/encoder/layer.5/attention/self/Shape_5_output_0: (Int64)[3]\n",
      "/encoder/layer.5/attention/self/Constant_7_output_0: (Int64)\n",
      "/encoder/layer.5/attention/self/Gather_5_output_0: (Int64)\n",
      "onnx::Unsqueeze_875: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Unsqueeze_2_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_877: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Unsqueeze_3_output_0: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Constant_8_output_0: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Constant_9_output_0: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Concat_1_output_0: (Int64)[4]\n",
      "/encoder/layer.5/attention/self/Reshape_1_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.5/attention/self/value/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/self/value/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/self/Shape_6_output_0: (Int64)[3]\n",
      "/encoder/layer.5/attention/self/Constant_10_output_0: (Int64)\n",
      "/encoder/layer.5/attention/self/Gather_6_output_0: (Int64)\n",
      "/encoder/layer.5/attention/self/Shape_7_output_0: (Int64)[3]\n",
      "/encoder/layer.5/attention/self/Constant_11_output_0: (Int64)\n",
      "/encoder/layer.5/attention/self/Gather_7_output_0: (Int64)\n",
      "onnx::Unsqueeze_894: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Unsqueeze_4_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_896: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Unsqueeze_5_output_0: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Constant_12_output_0: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Constant_13_output_0: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Concat_2_output_0: (Int64)[4]\n",
      "/encoder/layer.5/attention/self/Reshape_2_output_0: (Float32)[2 7 12 32]\n",
      "/encoder/layer.5/attention/self/Transpose_1_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.5/attention/self/Shape_8_output_0: (Int64)[4]\n",
      "/encoder/layer.5/attention/self/Constant_14_output_0: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Constant_15_output_0: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Slice_output_0: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Cast_output_0: (Float32)[1]\n",
      "/encoder/layer.5/attention/self/Sqrt_output_0: (Float32)[1]\n",
      "/encoder/layer.5/attention/self/Constant_16_output_0: (Float32)[1]\n",
      "/encoder/layer.5/attention/self/Div_output_0: (Float32)[1]\n",
      "/encoder/layer.5/attention/self/Cast_1_output_0: (Float32)[1]\n",
      "/encoder/layer.5/attention/self/Transpose_2_output_0: (Float32)[2 12 32 7]\n",
      "/encoder/layer.5/attention/self/Sqrt_1_output_0: (Float32)[1]\n",
      "/encoder/layer.5/attention/self/Mul_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.5/attention/self/Sqrt_2_output_0: (Float32)[1]\n",
      "/encoder/layer.5/attention/self/Mul_1_output_0: (Float32)[2 12 32 7]\n",
      "/encoder/layer.5/attention/self/MatMul_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.5/attention/self/Add_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.5/attention/self/Softmax_output_0: (Float32)[2 12 7 7]\n",
      "/encoder/layer.5/attention/self/MatMul_1_output_0: (Float32)[2 12 7 32]\n",
      "/encoder/layer.5/attention/self/Transpose_3_output_0: (Float32)[2 7 12 32]\n",
      "onnx::Unsqueeze_924: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Unsqueeze_6_output_0: (Int64)[1]\n",
      "onnx::Unsqueeze_926: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Unsqueeze_7_output_0: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Constant_17_output_0: (Int64)[1]\n",
      "/encoder/layer.5/attention/self/Concat_3_output_0: (Int64)[3]\n",
      "/encoder/layer.5/attention/self/Reshape_3_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/output/dense/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/output/dense/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/output/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.5/attention/output/LayerNorm/Sub_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/output/LayerNorm/Constant_output_0: (Float32)\n",
      "/encoder/layer.5/attention/output/LayerNorm/Pow_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.5/attention/output/LayerNorm/Add_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.5/attention/output/LayerNorm/Div_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/output/LayerNorm/Mul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/intermediate/dense/MatMul_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.5/intermediate/dense/Add_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0: (Float32)\n",
      "/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0: (Float32)\n",
      "/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0: (Float32)[2 7 1536]\n",
      "/encoder/layer.5/output/dense/MatMul_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/output/dense/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/output/Add_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/output/LayerNorm/ReduceMean_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.5/output/LayerNorm/Sub_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/output/LayerNorm/Constant_output_0: (Float32)\n",
      "/encoder/layer.5/output/LayerNorm/Pow_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.5/output/LayerNorm/Constant_1_output_0: (Float32)\n",
      "/encoder/layer.5/output/LayerNorm/Add_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.5/output/LayerNorm/Sqrt_output_0: (Float32)[2 7 1]\n",
      "/encoder/layer.5/output/LayerNorm/Div_output_0: (Float32)[2 7 384]\n",
      "/encoder/layer.5/output/LayerNorm/Mul_output_0: (Float32)[2 7 384]\n",
      "last_hidden_state: (Float32)[2 7 384]\n"
     ]
    }
   ],
   "source": [
    "func parseShapes() {\n",
    "    contents := string(must.M1(os.ReadFile(\"model_shapes.txt\")))\n",
    "    for _, line := range strings.Split(contents, \"\\n\") {\n",
    "        parts := strings.Split(line, \"\\t\")\n",
    "        if len(parts) != 3 {\n",
    "            continue\n",
    "        }\n",
    "        nodeOutputName := parts[0]\n",
    "        dtype := must.M1(dtypes.DTypeString(parts[1]))\n",
    "        dimsStr := parts[2]\n",
    "        dimsStr = strings.Trim(dimsStr, \"()\")\n",
    "        var dims []int\n",
    "        for _, dimStr := range strings.Split(dimsStr, \",\") {\n",
    "            if dimStr == \"\" {\n",
    "                continue\n",
    "            }\n",
    "            dimStr = strings.Trim(dimStr, \" \")\n",
    "            dims = append(dims, must.M1(strconv.Atoi(dimStr)))\n",
    "        }\n",
    "        wantShape := shapes.Make(dtype, dims...)\n",
    "        fmt.Printf(\"%s: %s\\n\", nodeOutputName, wantShape)\n",
    "        output := miniLM(false, nodeOutputName)[0]\n",
    "        if !output.Shape().Equal(wantShape) {\n",
    "            fmt.Printf(\"\\t*** got shape %s\\n\", output.Shape())\n",
    "        }\n",
    "    }\n",
    "}\n",
    "%%\n",
    "parseShapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e62783-71a4-4725-9b19-3ff8c33d5d94",
   "metadata": {},
   "source": [
    "### Last layer result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7e082eb2-567b-4ca5-860a-a8bcbbe78c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Model:\n",
      "\tProducer:\tpytorch / 2.5.0\n",
      "\t# inputs:\t3\n",
      "\t\t[#0] input_ids: (Int64) [batch_size, sequence_length]\n",
      "\t\t[#1] attention_mask: (Int64) [batch_size, sequence_length]\n",
      "\t\t[#2] token_type_ids: (Int64) [batch_size, sequence_length]\n",
      "\t# outputs:\t1\n",
      "\t\t[#0] last_hidden_state: (Float32) [batch_size, sequence_length, 384]\n",
      "\t# nodes:\t780\n",
      "\t# tensors (variables):\t101\n",
      "\t# sparse tensors (variables):\t0\n",
      "\tOp types:\t[]string{\"Add\", \"Cast\", \"Concat\", \"Constant\", \"ConstantOfShape\", \"Div\", \"Equal\", \"Erf\", \"Expand\", \"Gather\", \"MatMul\", \"Mul\", \"Pow\", \"ReduceMean\", \"Reshape\", \"Shape\", \"Slice\", \"Softmax\", \"Sqrt\", \"Sub\", \"Transpose\", \"Unsqueeze\", \"Where\"}\n",
      "\tIR Version:\t7\n",
      "\tOperator Sets:\t[v14]\n",
      "\n",
      "\n",
      "\n",
      "Example invocation:\n",
      "\tall-MiniLM-L6-v2([]string{\"This is an example sentence\", \"Each sentence is converted\"})=\n",
      "[2][7][384]float32{\n",
      " {{0.0366, -0.0162, 0.1682, ..., 0.0554, -0.1644, -0.2967},\n",
      "  {0.7239, 0.6399, 0.1888, ..., 0.5946, 0.6206, 0.4897},\n",
      "  {0.0064, 0.0203, 0.0448, ..., 0.3464, 1.3170, -0.1670},\n",
      "  ...,\n",
      "  {0.1479, -0.0643, 0.1457, ..., 0.8837, -0.3316, 0.2975},\n",
      "  {0.5212, 0.6563, 0.5607, ..., -0.0399, 0.0412, -1.4036},\n",
      "  {1.0824, 0.7140, 0.3986, ..., -0.2301, 0.3243, -1.0313}},\n",
      " {{0.2802, 0.1165, -0.0418, ..., 0.2711, -0.1685, -0.2961},\n",
      "  {0.8729, 0.4545, -0.1091, ..., 0.1365, 0.4580, -0.2042},\n",
      "  {0.4752, 0.5731, 0.6304, ..., 0.6526, 0.5612, -1.3268},\n",
      "  ...,\n",
      "  {0.6113, 0.7920, -0.4685, ..., 0.0854, 1.0592, -0.2983},\n",
      "  {0.4115, 1.0946, 0.2385, ..., 0.8984, 0.3684, -0.7333},\n",
      "  {0.1374, 0.5555, 0.2678, ..., 0.5426, 0.4665, -0.5284}}}\n"
     ]
    }
   ],
   "source": [
    "%%\n",
    "fmt.Printf(\"%s\\n\", miniLM(true)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.23.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
