{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f5cd05-8e1b-4873-8220-7cd7577da125",
   "metadata": {},
   "source": [
    "# Converting ONNX models to GoMLX\n",
    "\n",
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cdd74c0-e5af-45d6-93d8-7453b1a590f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**GoNB** version [v0.10.6](https://github.com/janpfeifer/gonb/releases/tag/v0.10.6) / Commit: [0e5f587a077810d058202b76a127651a02bd4382](https://github.com/janpfeifer/gonb/tree/0e5f587a077810d058202b76a127651a02bd4382)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Added replace rule for module \"github.com/gomlx/gomlx\" to local directory \"/home/janpf/Projects/gomlx\".\n",
      "\t- Added replace rule for module \"github.com/janpfeifer/gonb\" to local directory \"/home/janpf/Projects/gonb\".\n",
      "\t- Added replace rule for module \"github.com/gomlx/onnx-gomlx\" to local directory \"/home/janpf/Projects/onnx-gomlx\".\n"
     ]
    }
   ],
   "source": [
    "%version\n",
    "!*rm -f go.work && go work init\n",
    "!*go work use . \"${HOME}/Projects/gonb\" \"${HOME}/Projects/gomlx\" \"${HOME}/Projects/onnx-gomlx\"\n",
    "%goworkfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adeca919-f2ed-4d8b-93fb-6978f94de2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "\t\"fmt\"\n",
    "\t\"os\"\n",
    "\n",
    "\t\"github.com/gogo/protobuf/proto\"\n",
    "\t\"github.com/janpfeifer/must\"\n",
    "\n",
    "\t\"github.com/gomlx/gomlx/backends\"\n",
    "    . \"github.com/gomlx/gomlx/graph\"\n",
    "\t\"github.com/gomlx/gomlx/ml/context\"\n",
    "\t\"github.com/gomlx/gomlx/ml/data\"\n",
    "\t\"github.com/gomlx/gomlx/types\"\n",
    "    \"github.com/gomlx/onnx-gomlx/onnx\"\n",
    "\t\"github.com/pkg/errors\"\n",
    "\n",
    "\t_ \"github.com/gomlx/gomlx/backends/xla\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    _ = Add\n",
    "    backend = backends.New()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273d236-cb0d-4d92-a0f0-e9b9d6f6e156",
   "metadata": {},
   "source": [
    "## Linear Model\n",
    "\n",
    "The `linear_regression.onnx` was created manually using python (see accompanying `onnx-py.ipynb` notebook):\n",
    "\n",
    "```python\n",
    "feature_dim = 5\n",
    "X = make_tensor_value_info('X', TensorProto.FLOAT, [\"batch_size\", feature_dim])\n",
    "Y = make_tensor_value_info('Y', TensorProto.FLOAT, [\"batch_size\"])\n",
    "A_initializer = onnx.helper.make_tensor('A', TensorProto.FLOAT, [feature_dim], [100.0, 10.0, 1.0, 0.1, 0.01])\n",
    "B_initializer = onnx.helper.make_tensor('B', TensorProto.FLOAT, [], [7000.0])\n",
    "node1 = make_node('MatMul', ['X', 'A'], ['XA'], 'XA')\n",
    "node2 = make_node('Add', ['XA', 'B'], ['Y'], 'Y')\n",
    "graph = make_graph([node1, node2], 'lr', [X], [Y], initializer=[A_initializer, B_initializer])\n",
    "onnx_model = make_model(graph)\n",
    "check_model(onnx_model)\n",
    "with open(\"linear_regression.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c2fa3d-78e6-4283-be3d-1ccaa0ddffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Model:\n",
      "\t# inputs:\t1\n",
      "\t\t[#0] X: (Float32) [batch_size, 5]\n",
      "\t# outputs:\t1\n",
      "\t\t[#0] Y: (Float32) [batch_size]\n",
      "\t# nodes:\t2\n",
      "\t# tensors (variables):\t2\n",
      "\t# sparse tensors (variables):\t0\n",
      "\tOp types:\t[]string{\"Add\", \"MatMul\"}\n",
      "\tIR Version:\t10\n",
      "\tOperator Sets:\t[v21]\n",
      "\n",
      "2 tensors (variables):\n",
      "\t\"A\": (Float32)[5]\n",
      "\t\"B\": (Float32)\n",
      "0 sparse tensors (variables)\n",
      "\n",
      "Model Graph \"lr\":\n",
      "\"XA\":\t[MatMul]\n",
      "\tInputs: [\"X\" \"A\"]\n",
      "\tOutputs: [\"XA\"]\n",
      "\"Y\":\t[Add]\n",
      "\tInputs: [\"XA\" \"B\"]\n",
      "\tOutputs: [\"Y\"]\n",
      "\n",
      "Variables loaded from \"/home/janpf/work/onnx/linear_regression.onnx\":\n",
      "\t- /ONNX/A: (Float32)[5]: []float32{100, 10, 1, 0.1, 0.01}\n",
      "\t- /ONNX/B: float32(7000)\n",
      "\n",
      "Example invocation:\n",
      "\tX*A+B=(Float32)[2]: []float32{7123.45, 7679}\n"
     ]
    }
   ],
   "source": [
    "var modelPath = data.ReplaceTildeInDir(\"~/work/onnx/linear_regression.onnx\") // all-MiniLM-L6-v2\n",
    "\n",
    "%%\n",
    "// Read and print the onnx model:\n",
    "model := must.M1(onnx.ReadFile(modelPath))\n",
    "fmt.Printf(\"%s\\n\", model)\n",
    "must.M(model.PrintVariables(os.Stdout))\n",
    "fmt.Println()\n",
    "must.M(model.PrintGraph(os.Stdout))\n",
    "fmt.Println()\n",
    "\n",
    "// Convert ONNX variables to GoMLX context (which stores variables):\n",
    "ctx := context.New()\n",
    "must.M(model.VariablesToContext(ctx))\n",
    "fmt.Printf(\"Variables loaded from %q:\\n\", modelPath)\n",
    "for v := range ctx.IterVariables() {\n",
    "    fmt.Printf(\"\\t- %s: %s\\n\", v.ScopeAndName(), v.Value().GoStr())\n",
    "}\n",
    "fmt.Println()\n",
    "\n",
    "// Execute it with GoMLX/XLA:\n",
    "gomlxFn := func(ctx *context.Context, x *Node) *Node {\n",
    "    return model.CallGraph(ctx, x.Graph(), map[string]*Node{\"X\": x})[0]\n",
    "}\n",
    "x := [][]float32{{1, 2, 3, 4, 5}, {6, 7, 8, 9, 10}}\n",
    "fmt.Println(\"Example invocation:\")\n",
    "fmt.Printf(\"\\tX*A+B=%v\\n\", context.ExecOnce(backend, ctx, gomlxFn, x).GoStr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19434069-043d-4819-9cc7-1506ad31a143",
   "metadata": {},
   "source": [
    "## [Sentence Enconding all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "\n",
    "From the downloaded file `model.onnx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2240c215-8169-4e17-a64e-2628c2bbdca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "func miniLM(verbose bool, targetOutputs ...string) *tensors.Tensor {\n",
    "    modelPath = data.ReplaceTildeInDir(\"~/work/onnx/model.onnx\") // all-MiniLM-L6-v2\n",
    "    // Read and print the onnx model:\n",
    "    model := must.M1(onnx.ReadFile(modelPath))\n",
    "    if verbose {\n",
    "        fmt.Printf(\"%s\\n\", model)\n",
    "    }\n",
    "        \n",
    "    // Create a file for debugging with detailed graph.\n",
    "    if verbose {\n",
    "        debugFile := must.M1(os.Create(\"graph.txt\"))\n",
    "        must.M(model.PrintVariables(debugFile))\n",
    "        fmt.Println()\n",
    "        must.M(model.PrintGraph(debugFile))\n",
    "        fmt.Println()\n",
    "        must.M(debugFile.Close())\n",
    "    }\n",
    "    \n",
    "    // Convert ONNX variables to GoMLX context (which stores variables):\n",
    "    ctx := context.New()\n",
    "    must.M(model.VariablesToContext(ctx))\n",
    "    \n",
    "    // Execute it with GoMLX/XLA:\n",
    "    gomlxFn := func(ctx *context.Context, inputIDs, attentionMask, tokenTypeIDs *Node) *Node {\n",
    "        outputs := model.CallGraph(ctx, inputIDs.Graph(), map[string]*Node{\n",
    "            \"input_ids\": inputIDs,\n",
    "            \"attention_mask\": attentionMask,\n",
    "            \"token_type_ids\": tokenTypeIDs}, targetOutputs...)\n",
    "        return outputs[0]\n",
    "    }\n",
    "    sentences := []string{\n",
    "        \"This is an example sentence\", \n",
    "        \"Each sentence is converted\"}\n",
    "    // Encoding to tokens done in Python and pasted here.\n",
    "    inputIDs := [][]int64{\n",
    "        {101, 2023, 2003, 2019, 2742, 6251,  102},\n",
    "        { 101, 2169, 6251, 2003, 4991,  102,    0}}\n",
    "    tokenTypeIDs := [][]int64{\n",
    "        {0, 0, 0, 0, 0, 0, 0},\n",
    "        {0, 0, 0, 0, 0, 0, 0}}\n",
    "    attentionMask := [][]int64{\n",
    "        {1, 1, 1, 1, 1, 1, 1},\n",
    "        {1, 1, 1, 1, 1, 1, 0}}\n",
    "    fmt.Println(\"Example invocation:\")\n",
    "    fmt.Printf(\"\\tall-MiniLM-L6-v2(%#v)=\\n\", sentences)\n",
    "    var embeddings *tensors.Tensor\n",
    "    err := exceptions.TryCatch[error](func() {\n",
    "        embeddings = context.ExecOnce(backend, ctx, gomlxFn, inputIDs, tokenTypeIDs, attentionMask)\n",
    "    })\n",
    "    must.M(err)\n",
    "    return embeddings\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b62fcf64-49b1-4f2b-b0f1-cb77dd5838d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set: GOMLX_BACKEND=\"xla:cuda\"\n",
      "Example invocation:\n",
      "\tall-MiniLM-L6-v2([]string{\"This is an example sentence\", \"Each sentence is converted\"})=\n",
      "[2][7][384]float32{\n",
      " {{-0.0176, -0.0076, 0.0471, ..., -0.0545, 0.0076, -0.0617},\n",
      "  {-0.0019, -0.0074, -0.0267, ..., -0.0010, 0.0197, 0.1891},\n",
      "  {-0.0208, -0.0279, -0.0515, ..., 0.0207, 0.0377, 0.0610},\n",
      "  ...,\n",
      "  {-0.0086, 0.0210, -0.0081, ..., -0.0094, 0.0128, 0.1179},\n",
      "  {-0.0039, -0.0451, 0.0609, ..., -0.0773, 0.0549, -0.0595},\n",
      "  {0.0332, -0.0085, -0.0400, ..., 0.0207, -0.0034, -0.0004}},\n",
      " {{-0.0176, -0.0076, 0.0471, ..., -0.0545, 0.0076, -0.0617},\n",
      "  {0.0485, 0.0471, -0.0329, ..., -0.1225, -0.0107, 0.0374},\n",
      "  {-0.0039, -0.0451, 0.0609, ..., -0.0773, 0.0549, -0.0595},\n",
      "  ...,\n",
      "  {0.1095, -0.0033, -0.1182, ..., 0.0625, 0.0140, -0.0135},\n",
      "  {0.0332, -0.0085, -0.0400, ..., 0.0207, -0.0034, -0.0004},\n",
      "  {-0.0200, -0.0034, -0.0147, ..., 0.0381, -0.0054, 0.0311}}}"
     ]
    }
   ],
   "source": [
    "%env GOMLX_BACKEND=\"xla:cuda\"\n",
    "%%\n",
    "embeddings := miniLM(true, \"/embeddings/word_embeddings/Gather_output_0\")\n",
    "fmt.Printf(\"%s\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1a964b00-5b3a-45b2-bfab-4e025026187c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=8064\n",
      "[3][7][384]float32{\n",
      " {{1.0000, 2.0000, 3.0000, ..., 382.0000, 383.0000, 384.0000},\n",
      "  {385.0000, 386.0000, 387.0000, ..., 766.0000, 767.0000, 768.0000},\n",
      "  {769.0000, 770.0000, 771.0000, ..., 1150.0000, 1151.0000, 1152.0000},\n",
      "  ...,\n",
      "  {1537.0000, 1538.0000, 1539.0000, ..., 1918.0000, 1919.0000, 1920.0000},\n",
      "  {1921.0000, 1922.0000, 1923.0000, ..., 2302.0000, 2303.0000, 2304.0000},\n",
      "  {2305.0000, 2306.0000, 2307.0000, ..., 2686.0000, 2687.0000, 2688.0000}},\n",
      " ...,\n",
      " {{5377.0000, 5378.0000, 5379.0000, ..., 5758.0000, 5759.0000, 5760.0000},\n",
      "  {5761.0000, 5762.0000, 5763.0000, ..., 6142.0000, 6143.0000, 6144.0000},\n",
      "  {6145.0000, 6146.0000, 6147.0000, ..., 6526.0000, 6527.0000, 6528.0000},\n",
      "  ...,\n",
      "  {6913.0000, 6914.0000, 6915.0000, ..., 7294.0000, 7295.0000, 7296.0000},\n",
      "  {7297.0000, 7298.0000, 7299.0000, ..., 7678.0000, 7679.0000, 7680.0000},\n",
      "  {7681.0000, 7682.0000, 7683.0000, ..., 8062.0000, 8063.0000, 8064.0000}}}\n"
     ]
    }
   ],
   "source": [
    "%%\n",
    "shape := shapes.Make(dtypes.F32, 3, 7, 384)\n",
    "fmt.Printf(\"size=%d\\n\", shape.Size())\n",
    "t := tensors.FromFlatDataAndDimensions(xslices.Iota(float32(1), shape.Size()), shape.Dimensions...)\n",
    "fmt.Printf(\"%s\\n\", t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.23.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
