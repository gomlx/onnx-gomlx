{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f5cd05-8e1b-4873-8220-7cd7577da125",
   "metadata": {},
   "source": [
    "# Converting ONNX models to GoMLX\n",
    "\n",
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cdd74c0-e5af-45d6-93d8-7453b1a590f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**GoNB** version [v0.10.6](https://github.com/janpfeifer/gonb/releases/tag/v0.10.6) / Commit: [0e5f587a077810d058202b76a127651a02bd4382](https://github.com/janpfeifer/gonb/tree/0e5f587a077810d058202b76a127651a02bd4382)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Added replace rule for module \"github.com/janpfeifer/gonb\" to local directory \"/home/janpf/Projects/gonb\".\n",
      "\t- Added replace rule for module \"github.com/gomlx/onnx-gomlx\" to local directory \"/home/janpf/Projects/onnx-gomlx\".\n",
      "\t- Added replace rule for module \"github.com/gomlx/gomlx\" to local directory \"/home/janpf/Projects/gomlx\".\n"
     ]
    }
   ],
   "source": [
    "%version\n",
    "!*rm -f go.work && go work init\n",
    "!*go work use . \"${HOME}/Projects/gonb\" \"${HOME}/Projects/gomlx\" \"${HOME}/Projects/onnx-gomlx\"\n",
    "%goworkfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adeca919-f2ed-4d8b-93fb-6978f94de2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "\t\"fmt\"\n",
    "\t\"os\"\n",
    "\n",
    "\t\"github.com/gogo/protobuf/proto\"\n",
    "\t\"github.com/janpfeifer/must\"\n",
    "\n",
    "\t\"github.com/gomlx/gomlx/backends\"\n",
    "    . \"github.com/gomlx/gomlx/graph\"\n",
    "\t\"github.com/gomlx/gomlx/ml/context\"\n",
    "\t\"github.com/gomlx/gomlx/ml/data\"\n",
    "\t\"github.com/gomlx/gomlx/types\"\n",
    "    \"github.com/gomlx/onnx-gomlx/onnx\"\n",
    "\t\"github.com/pkg/errors\"\n",
    "\n",
    "\t_ \"github.com/gomlx/gomlx/backends/xla\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    _ = Add\n",
    "    backend = backends.New()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273d236-cb0d-4d92-a0f0-e9b9d6f6e156",
   "metadata": {},
   "source": [
    "## Linear Model\n",
    "\n",
    "The `linear_regression.onnx` was created manually using python (see accompanying `onnx-py.ipynb` notebook):\n",
    "\n",
    "```python\n",
    "feature_dim = 5\n",
    "X = make_tensor_value_info('X', TensorProto.FLOAT, [\"batch_size\", feature_dim])\n",
    "Y = make_tensor_value_info('Y', TensorProto.FLOAT, [\"batch_size\"])\n",
    "A_initializer = onnx.helper.make_tensor('A', TensorProto.FLOAT, [feature_dim], [100.0, 10.0, 1.0, 0.1, 0.01])\n",
    "B_initializer = onnx.helper.make_tensor('B', TensorProto.FLOAT, [], [7000.0])\n",
    "node1 = make_node('MatMul', ['X', 'A'], ['XA'], 'XA')\n",
    "node2 = make_node('Add', ['XA', 'B'], ['Y'], 'Y')\n",
    "graph = make_graph([node1, node2], 'lr', [X], [Y], initializer=[A_initializer, B_initializer])\n",
    "onnx_model = make_model(graph)\n",
    "check_model(onnx_model)\n",
    "with open(\"linear_regression.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0c2fa3d-78e6-4283-be3d-1ccaa0ddffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Model:\n",
      "\t# inputs:\t1\n",
      "\t\t[#0] X: (Float32) [batch_size, 5]\n",
      "\t# outputs:\t1\n",
      "\t\t[#0] Y: (Float32) [batch_size]\n",
      "\t# nodes:\t2\n",
      "\t# tensors (variables):\t2\n",
      "\t# sparse tensors (variables):\t0\n",
      "\tOp types:\t[]string{\"Add\", \"MatMul\"}\n",
      "\tIR Version:\t10\n",
      "\tOperator Sets:\t[v21]\n",
      "\n",
      "2 tensors (variables):\n",
      "\t\"A\": (Float32)[5]\n",
      "\t\"B\": (Float32)\n",
      "0 sparse tensors (variables)\n",
      "\n",
      "Model Graph \"lr\":\n",
      "\"XA\":\t[MatMul]\n",
      "\tInputs: [\"X\" \"A\"]\n",
      "\tOutputs: [\"XA\"]\n",
      "\"Y\":\t[Add]\n",
      "\tInputs: [\"XA\" \"B\"]\n",
      "\tOutputs: [\"Y\"]\n",
      "\n",
      "Variables loaded from \"/home/janpf/work/onnx/linear_regression.onnx\":\n",
      "\t- /ONNX/A: (Float32)[5]: []float32{100, 10, 1, 0.1, 0.01}\n",
      "\t- /ONNX/B: float32(7000)\n",
      "\n",
      "Example invocation:\n",
      "\tX*A+B=(Float32)[2]: []float32{7123.45, 7679}\n"
     ]
    }
   ],
   "source": [
    "var modelPath = data.ReplaceTildeInDir(\"~/work/onnx/linear_regression.onnx\") // all-MiniLM-L6-v2\n",
    "\n",
    "%%\n",
    "// Read and print the onnx model:\n",
    "model := must.M1(onnx.ReadFile(modelPath))\n",
    "fmt.Printf(\"%s\\n\", model)\n",
    "must.M(model.PrintVariables(os.Stdout))\n",
    "fmt.Println()\n",
    "must.M(model.PrintGraph(os.Stdout))\n",
    "fmt.Println()\n",
    "\n",
    "// Convert ONNX variables to GoMLX context (which stores variables):\n",
    "ctx := context.New()\n",
    "must.M(model.VariablesToContext(ctx))\n",
    "fmt.Printf(\"Variables loaded from %q:\\n\", modelPath)\n",
    "for v := range ctx.IterVariables() {\n",
    "    fmt.Printf(\"\\t- %s: %s\\n\", v.ScopeAndName(), v.Value().GoStr())\n",
    "}\n",
    "fmt.Println()\n",
    "\n",
    "// Execute it with GoMLX/XLA:\n",
    "gomlxFn := func(ctx *context.Context, x *Node) *Node {\n",
    "    return model.CallGraph(ctx, []*Node{x})[0]\n",
    "}\n",
    "x := [][]float32{{1, 2, 3, 4, 5}, {6, 7, 8, 9, 10}}\n",
    "fmt.Println(\"Example invocation:\")\n",
    "fmt.Printf(\"\\tX*A+B=%v\\n\", context.ExecOnce(backend, ctx, gomlxFn, x).GoStr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19434069-043d-4819-9cc7-1506ad31a143",
   "metadata": {},
   "source": [
    "## [Sentence Enconding all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "\n",
    "From the downloaded file `model.onnx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2240c215-8169-4e17-a64e-2628c2bbdca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Model:\n",
      "\tProducer:\tpytorch / 2.5.0\n",
      "\t# inputs:\t3\n",
      "\t\t[#0] input_ids: (Int64) [batch_size, sequence_length]\n",
      "\t\t[#1] attention_mask: (Int64) [batch_size, sequence_length]\n",
      "\t\t[#2] token_type_ids: (Int64) [batch_size, sequence_length]\n",
      "\t# outputs:\t1\n",
      "\t\t[#0] last_hidden_state: (Float32) [batch_size, sequence_length, 384]\n",
      "\t# nodes:\t780\n",
      "\t# tensors (variables):\t101\n",
      "\t# sparse tensors (variables):\t0\n",
      "\tOp types:\t[]string{\"Add\", \"Cast\", \"Concat\", \"Constant\", \"ConstantOfShape\", \"Div\", \"Equal\", \"Erf\", \"Expand\", \"Gather\", \"MatMul\", \"Mul\", \"Pow\", \"ReduceMean\", \"Reshape\", \"Shape\", \"Slice\", \"Softmax\", \"Sqrt\", \"Sub\", \"Transpose\", \"Unsqueeze\", \"Where\"}\n",
      "\tIR Version:\t7\n",
      "\tOperator Sets:\t[v14]\n",
      "\n",
      "Example invocation:\n",
      "\tall-MiniLM-L6-v2([]string{\"This is an example sentence\", \"Each sentence is converted\"})=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/29 09:24:57 Must not error: unimplemented ONNX Node \"/Unsqueeze\" [Unsqueeze](attention_mask, /Constant_3_output_0) -> /Unsqueeze_output_0\n",
      "github.com/gomlx/exceptions.Panicf\n",
      "\t/home/janpf/src/go/pkg/mod/github.com/gomlx/exceptions@v0.0.3/exceptions.go:92\n",
      "github.com/gomlx/onnx-gomlx/onnx.(*Model).convertNode\n",
      "\t/home/janpf/Projects/onnx-gomlx/onnx/graph.go:256\n",
      "github.com/gomlx/onnx-gomlx/onnx.(*Model).CallGraph.func2\n",
      "\t/home/janpf/Projects/onnx-gomlx/onnx/graph.go:98\n",
      "github.com/gomlx/exceptions.TryCatch[...]\n",
      "\t/home/janpf/src/go/pkg/mod/github.com/gomlx/exceptions@v0.0.3/exceptions.go:85\n",
      "github.com/gomlx/onnx-gomlx/onnx.(*Model).CallGraph\n",
      "\t/home/janpf/Projects/onnx-gomlx/onnx/graph.go:98\n",
      "main.main.func1\n",
      "\t \u001b[7m[[ Cell [45] Line 18 ]]\u001b[0m /tmp/gonb_7657010d/main.go:41\n",
      "reflect.Value.call\n",
      "\t/snap/go/current/src/reflect/value.go:581\n",
      "reflect.Value.Call\n",
      "\t/snap/go/current/src/reflect/value.go:365\n",
      "github.com/gomlx/gomlx/ml/context.(*Exec).buildGraphFn.func1\n",
      "\t/home/janpf/Projects/gomlx/ml/context/exec.go:312\n",
      "reflect.Value.call\n",
      "\t/snap/go/current/src/reflect/value.go:581\n",
      "reflect.Value.Call\n",
      "\t/snap/go/current/src/reflect/value.go:365\n",
      "github.com/gomlx/gomlx/graph.(*Exec).createAndCacheGraph\n",
      "\t/home/janpf/Projects/gomlx/graph/exec.go:536\n",
      "github.com/gomlx/gomlx/graph.(*Exec).findOrCreateGraph\n",
      "\t/home/janpf/Projects/gomlx/graph/exec.go:595\n",
      "github.com/gomlx/gomlx/graph.(*Exec).compileAndExecute\n",
      "\t/home/janpf/Projects/gomlx/graph/exec.go:436\n",
      "github.com/gomlx/gomlx/graph.(*Exec).CallWithGraph\n",
      "\t/home/janpf/Projects/gomlx/graph/exec.go:386\n",
      "github.com/gomlx/gomlx/ml/context.(*Exec).CallWithGraph\n",
      "\t/home/janpf/Projects/gomlx/ml/context/exec.go:539\n",
      "github.com/gomlx/gomlx/ml/context.(*Exec).Call\n",
      "\t/home/janpf/Projects/gomlx/ml/context/exec.go:525\n",
      "github.com/gomlx/gomlx/ml/context.ExecOnceN[...]\n",
      "\t/home/janpf/Projects/gomlx/ml/context/exec.go:451\n",
      "github.com/gomlx/gomlx/ml/context.ExecOnce[...]\n",
      "\t/home/janpf/Projects/gomlx/ml/context/exec.go:460\n",
      "main.main.func2\n",
      "\t \u001b[7m[[ Cell [45] Line 37 ]]\u001b[0m /tmp/gonb_7657010d/main.go:60\n",
      "github.com/gomlx/exceptions.TryCatch[...]\n",
      "\t/home/janpf/src/go/pkg/mod/github.com/gomlx/exceptions@v0.0.3/exceptions.go:85\n",
      "main.main\n",
      "\t \u001b[7m[[ Cell [45] Line 36 ]]\u001b[0m /tmp/gonb_7657010d/main.go:59\n",
      "runtime.main\n",
      "\t/snap/go/current/src/runtime/proc.go:272\n",
      "runtime.goexit\n",
      "\t/snap/go/current/src/runtime/asm_amd64.s:1700\n",
      "while converting node 220 out of 780\n",
      "Panicking ...\n",
      "\n",
      "panic: while converting node 220 out of 780: unimplemented ONNX Node \"/Unsqueeze\" [Unsqueeze](attention_mask, /Constant_3_output_0) -> /Unsqueeze_output_0\n",
      "\n",
      "goroutine 1 [running]:\n",
      "github.com/janpfeifer/must.init.func1({0xd91de0, 0xc0004a71c0})\n",
      "\t/home/janpf/src/go/pkg/mod/github.com/janpfeifer/must@v0.2.0/must.go:13 +0xd3\n",
      "main.main()\n",
      "\t \u001b[7m[[ Cell [45] Line 39 ]]\u001b[0m /tmp/gonb_7657010d/main.go:62 +0x6e5\n",
      "exit status 2\n"
     ]
    }
   ],
   "source": [
    "var modelPath = data.ReplaceTildeInDir(\"~/work/onnx/model.onnx\") // all-MiniLM-L6-v2\n",
    "\n",
    "%%\n",
    "// Read and print the onnx model:\n",
    "model := must.M1(onnx.ReadFile(modelPath))\n",
    "fmt.Printf(\"%s\\n\", model)\n",
    "// must.M(model.PrintVariables(os.Stdout))\n",
    "// fmt.Println()\n",
    "// must.M(model.PrintGraph(os.Stdout))\n",
    "// fmt.Println()\n",
    "\n",
    "// Convert ONNX variables to GoMLX context (which stores variables):\n",
    "ctx := context.New()\n",
    "must.M(model.VariablesToContext(ctx))\n",
    "\n",
    "// Execute it with GoMLX/XLA:\n",
    "gomlxFn := func(ctx *context.Context, inputIDs, attentionMask, tokenTypeIDs *Node) *Node {\n",
    "    return model.CallGraph(ctx, []*Node{inputIDs, attentionMask, tokenTypeIDs})[0]\n",
    "}\n",
    "sentences := []string{\n",
    "    \"This is an example sentence\", \n",
    "    \"Each sentence is converted\"}\n",
    "// Encoding to tokens done in Python and pasted here.\n",
    "inputIDs := [][]int64{\n",
    "    {101, 2023, 2003, 2019, 2742, 6251,  102},\n",
    "    { 101, 2169, 6251, 2003, 4991,  102,    0}}\n",
    "tokenTypeIDs := [][]int64{\n",
    "    {0, 0, 0, 0, 0, 0, 0},\n",
    "    {0, 0, 0, 0, 0, 0, 0}}\n",
    "attentionMask := [][]int64{\n",
    "    {1, 1, 1, 1, 1, 1, 1},\n",
    "    {1, 1, 1, 1, 1, 1, 0}}\n",
    "fmt.Println(\"Example invocation:\")\n",
    "fmt.Printf(\"\\tall-MiniLM-L6-v2(%#v)=\\n\", sentences)\n",
    "var embeddings *tensors.Tensor\n",
    "err := exceptions.TryCatch[error](func() {\n",
    "    embeddings = context.ExecOnce(backend, ctx, gomlxFn, inputIDs, tokenTypeIDs, attentionMask)\n",
    "})\n",
    "must.M(err)\n",
    "fmt.Printf(\"%s\", embeddings.GoStr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b62fcf64-49b1-4f2b-b0f1-cb77dd5838d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "go: downloading github.com/janpfeifer/must v0.2.0\n",
      "go: upgraded github.com/janpfeifer/must v0.1.0 => v0.2.0\n"
     ]
    }
   ],
   "source": [
    "!*GONOPROXY=\"*\" go get -u github.com/janpfeifer/must"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.23.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
