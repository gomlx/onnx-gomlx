{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f5cd05-8e1b-4873-8220-7cd7577da125",
   "metadata": {},
   "source": [
    "# Converting ONNX models to GoMLX\n",
    "\n",
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cdd74c0-e5af-45d6-93d8-7453b1a590f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**GoNB** version [v0.10.6](https://github.com/janpfeifer/gonb/releases/tag/v0.10.6) / Commit: [0e5f587a077810d058202b76a127651a02bd4382](https://github.com/janpfeifer/gonb/tree/0e5f587a077810d058202b76a127651a02bd4382)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Replace rule for module \"github.com/gomlx/go-huggingface\" to local directory \"/home/janpf/Projects/go-huggingface\" already exists.\n",
      "\t- Replace rule for module \"github.com/gomlx/gomlx\" to local directory \"/home/janpf/Projects/gomlx\" already exists.\n",
      "\t- Replace rule for module \"github.com/janpfeifer/gonb\" to local directory \"/home/janpf/Projects/gonb\" already exists.\n",
      "\t- Replace rule for module \"github.com/gomlx/onnx-gomlx\" to local directory \"/home/janpf/Projects/onnx-gomlx\" already exists.\n"
     ]
    }
   ],
   "source": [
    "%version\n",
    "!*rm -f go.work && go work init\n",
    "!*go work use . \"${HOME}/Projects/gonb\" \"${HOME}/Projects/gomlx\" \"${HOME}/Projects/onnx-gomlx\" \"${HOME}/Projects/go-huggingface\"\n",
    "%goworkfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adeca919-f2ed-4d8b-93fb-6978f94de2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "\t\"fmt\"\n",
    "\t\"os\"\n",
    "\n",
    "\t\"github.com/gogo/protobuf/proto\"\n",
    "\t\"github.com/janpfeifer/must\"\n",
    "\n",
    "\t\"github.com/gomlx/gomlx/backends\"\n",
    "    . \"github.com/gomlx/gomlx/graph\"\n",
    "\t\"github.com/gomlx/gomlx/ml/context\"\n",
    "\t\"github.com/gomlx/gomlx/ml/data\"\n",
    "\t\"github.com/gomlx/gomlx/types\"\n",
    "\t\"github.com/gomlx/gopjrt/dtypes\"\n",
    "    \"github.com/gomlx/onnx-gomlx/onnx\"\n",
    "    \"github.com/gomlx/go-huggingface/hub\"\n",
    "    \"github.com/gomlx/go-huggingface/tokenizers\"\n",
    "\t\"github.com/pkg/errors\"\n",
    "\n",
    "\t_ \"github.com/gomlx/gomlx/backends/xla\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    _ = Add\n",
    "    backend = backends.New()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273d236-cb0d-4d92-a0f0-e9b9d6f6e156",
   "metadata": {},
   "source": [
    "## Linear Model\n",
    "\n",
    "The `linear_regression.onnx` was created manually using python (see accompanying `onnx-py.ipynb` notebook):\n",
    "\n",
    "```python\n",
    "feature_dim = 5\n",
    "X = make_tensor_value_info('X', TensorProto.FLOAT, [\"batch_size\", feature_dim])\n",
    "Y = make_tensor_value_info('Y', TensorProto.FLOAT, [\"batch_size\"])\n",
    "A_initializer = onnx.helper.make_tensor('A', TensorProto.FLOAT, [feature_dim], [100.0, 10.0, 1.0, 0.1, 0.01])\n",
    "B_initializer = onnx.helper.make_tensor('B', TensorProto.FLOAT, [], [7000.0])\n",
    "node1 = make_node('MatMul', ['X', 'A'], ['XA'], 'XA')\n",
    "node2 = make_node('Add', ['XA', 'B'], ['Y'], 'Y')\n",
    "graph = make_graph([node1, node2], 'lr', [X], [Y], initializer=[A_initializer, B_initializer])\n",
    "onnx_model = make_model(graph)\n",
    "check_model(onnx_model)\n",
    "with open(\"linear_regression.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c2fa3d-78e6-4283-be3d-1ccaa0ddffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Model:\n",
      "\t# inputs:\t1\n",
      "\t\t[#0] X: (Float32) [batch_size, 5]\n",
      "\t# outputs:\t1\n",
      "\t\t[#0] Y: (Float32) [batch_size]\n",
      "\t# nodes:\t2\n",
      "\t# tensors (variables):\t2\n",
      "\t# sparse tensors (variables):\t0\n",
      "\tOp types:\t[]string{\"Add\", \"MatMul\"}\n",
      "\tIR Version:\t10\n",
      "\tOperator Sets:\t[v21]\n",
      "\n",
      "2 tensors (variables):\n",
      "\t\"A\": (Float32)[5]\n",
      "\t\"B\": (Float32)\n",
      "0 sparse tensors (variables)\n",
      "\n",
      "Model Graph \"lr\":\n",
      "\"XA\":\t[MatMul]\n",
      "\tInputs: [\"X\" \"A\"]\n",
      "\tOutputs: [\"XA\"]\n",
      "\"Y\":\t[Add]\n",
      "\tInputs: [\"XA\" \"B\"]\n",
      "\tOutputs: [\"Y\"]\n",
      "\n",
      "Variables loaded from \"/home/janpf/work/onnx/linear_regression.onnx\":\n",
      "\t- /ONNX/A: (Float32)[5]: []float32{100, 10, 1, 0.1, 0.01}\n",
      "\t- /ONNX/B: float32(7000)\n",
      "\n",
      "Example invocation:\n",
      "\tX*A+B=(Float32)[2]: []float32{7123.45, 7679}\n"
     ]
    }
   ],
   "source": [
    "var modelPath = data.ReplaceTildeInDir(\"~/work/onnx/linear_regression.onnx\") // all-MiniLM-L6-v2\n",
    "\n",
    "%%\n",
    "// Read and print the onnx model:\n",
    "model := must.M1(onnx.ReadFile(modelPath))\n",
    "fmt.Printf(\"%s\\n\", model)\n",
    "must.M(model.PrintVariables(os.Stdout))\n",
    "fmt.Println()\n",
    "must.M(model.PrintGraph(os.Stdout))\n",
    "fmt.Println()\n",
    "\n",
    "// Convert ONNX variables to GoMLX context (which stores variables):\n",
    "ctx := context.New()\n",
    "must.M(model.VariablesToContext(ctx))\n",
    "fmt.Printf(\"Variables loaded from %q:\\n\", modelPath)\n",
    "for v := range ctx.IterVariables() {\n",
    "    fmt.Printf(\"\\t- %s: %s\\n\", v.ScopeAndName(), v.Value().GoStr())\n",
    "}\n",
    "fmt.Println()\n",
    "\n",
    "// Execute it with GoMLX/XLA:\n",
    "gomlxFn := func(ctx *context.Context, x *Node) *Node {\n",
    "    return model.CallGraph(ctx, x.Graph(), map[string]*Node{\"X\": x})[0]\n",
    "}\n",
    "x := [][]float32{{1, 2, 3, 4, 5}, {6, 7, 8, 9, 10}}\n",
    "fmt.Println(\"Example invocation:\")\n",
    "fmt.Printf(\"\\tX*A+B=%v\\n\", context.ExecOnce(backend, ctx, gomlxFn, x).GoStr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19434069-043d-4819-9cc7-1506ad31a143",
   "metadata": {},
   "source": [
    "## [Sentence Enconding all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "\n",
    "From the downloaded file `model.onnx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2240c215-8169-4e17-a64e-2628c2bbdca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "var (\n",
    "    // Model IDs to use.\n",
    "    miniID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    bertID = \"KnightsAnalytics/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    protectID = \"protectai/deberta-v3-base-zeroshot-v1-onnx\"\n",
    "    robertaID = \"SamLowe/roberta-base-go_emotions-onnx\"\n",
    ")\n",
    "\n",
    "func onnxTest(modelID string, verbose bool, targetOutputs ...string) []*tensors.Tensor {\n",
    "    repo := hub.New(modelID)\n",
    "    modelFileName := \"model.onnx\"\n",
    "    if !repo.HasFile(modelFileName) { \n",
    "        modelFileName = \"onnx/model.onnx\"\n",
    "        if !repo.HasFile(modelFileName) { \n",
    "            log.Printf(\"Could not find \\\"model.onnx\\\" for repo %q\", repo)\n",
    "        }\n",
    "    }\n",
    "    modelPath := must.M1(repo.DownloadFile(modelFileName))\n",
    "    model := must.M1(onnx.ReadFile(modelPath))\n",
    "    if verbose {\n",
    "        fmt.Printf(\"\\n%s\\n\", modelID)\n",
    "        fmt.Printf(\"%s\\n\", model)\n",
    "    }\n",
    "        \n",
    "    // Create a file for debugging with detailed graph.\n",
    "    if verbose {\n",
    "        debugFile := must.M1(os.Create(\"graph.txt\"))\n",
    "        must.M(model.PrintVariables(debugFile))\n",
    "        fmt.Println()\n",
    "        must.M(model.PrintGraph(debugFile))\n",
    "        fmt.Println()\n",
    "        must.M(debugFile.Close())\n",
    "\n",
    "        dotFile := must.M1(os.Create(\"graph.dot\"))\n",
    "        must.M(model.PrintGraphviz(dotFile))\n",
    "        must.M(dotFile.Close())\n",
    "    }\n",
    "    \n",
    "    // Convert ONNX variables to GoMLX context (which stores variables):\n",
    "    ctx := context.New()\n",
    "    must.M(model.VariablesToContext(ctx))\n",
    "    \n",
    "    // Execute it with GoMLX/XLA:\n",
    "    sentences := []string{\n",
    "        \"This is an example sentence\", \n",
    "        \"Each sentence is converted\"}\n",
    "\n",
    "    // Encoding to tokens done in Python and pasted here.\n",
    "    inputIDs := [][]int64{\n",
    "        {101, 2023, 2003, 2019, 2742, 6251,  102},\n",
    "        { 101, 2169, 6251, 2003, 4991,  102,    0}}\n",
    "    tokenTypeIDs := [][]int64{\n",
    "        {0, 0, 0, 0, 0, 0, 0},\n",
    "        {0, 0, 0, 0, 0, 0, 0}}\n",
    "    attentionMask := [][]int64{\n",
    "        {1, 1, 1, 1, 1, 1, 1},\n",
    "        {1, 1, 1, 1, 1, 1, 0}}\n",
    "    if verbose {\n",
    "        fmt.Println(\"Example invocation:\")\n",
    "        fmt.Printf(\"\\tsentences: %q\\n\", sentences)\n",
    "    }\n",
    "    var embeddings []*tensors.Tensor\n",
    "    err := exceptions.TryCatch[error](func() {\n",
    "        embeddings = context.ExecOnceN(\n",
    "            backend, ctx, func (ctx *context.Context, inputs []*Node) []*Node {\n",
    "                inputsMap := map[string]*Node{\n",
    "                    \"input_ids\": inputs[0],\n",
    "                    \"attention_mask\": inputs[1]}\n",
    "                if model.NumInputs() == 3 {\n",
    "                    inputsMap[\"token_type_ids\"] = inputs[2]\n",
    "                }\n",
    "                return model.CallGraph(ctx, inputs[0].Graph(), inputsMap, targetOutputs...)\n",
    "            }, inputIDs, attentionMask, tokenTypeIDs)\n",
    "    })\n",
    "    must.M(err)\n",
    "    return embeddings\n",
    "}\n",
    "\n",
    "func p(modelID, target string) {\n",
    "    output := onnxTest(modelID, false, target)[0]\n",
    "    fmt.Printf(\"\\n%s:\\n\", target)\n",
    "    fmt.Printf(\"%s\\n\", output)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e62783-71a4-4725-9b19-3ff8c33d5d94",
   "metadata": {},
   "source": [
    "### Last layer result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4de6e20-c0ae-47df-b9f0-6f6f86f6c466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SamLowe/roberta-base-go_emotions-onnx\n",
      "ONNX Model:\n",
      "\tProducer:\tpytorch / 2.0.1\n",
      "\t# inputs:\t2\n",
      "\t\t[#0] input_ids: (Int64) [batch_size, sequence_length]\n",
      "\t\t[#1] attention_mask: (Int64) [batch_size, sequence_length]\n",
      "\t# outputs:\t1\n",
      "\t\t[#0] logits: (Float32) [batch_size, 28]\n",
      "\t# nodes:\t641\n",
      "\t# tensors (variables):\t362\n",
      "\t# sparse tensors (variables):\t0\n",
      "\tOp types:\t[]string{\"Add\", \"Cast\", \"Concat\", \"CumSum\", \"Div\", \"Equal\", \"Erf\", \"Expand\", \"Gather\", \"Gemm\", \"MatMul\", \"Mul\", \"Not\", \"Pow\", \"ReduceMean\", \"Reshape\", \"Shape\", \"Slice\", \"Softmax\", \"Sqrt\", \"Sub\", \"Tanh\", \"Transpose\", \"Unsqueeze\", \"Where\"}\n",
      "\tIR Version:\t6\n",
      "\tOperator Sets:\t[v11, v3 (ai.onnx.ml), v1 (ai.onnx.training), v19 (com.ms.internal.nhwc), v1 (ai.onnx.preview.training), v1 (com.microsoft), v1 (com.microsoft.experimental), v1 (com.microsoft.nchwc), v1 (org.pytorch.aten)]\n",
      "\n",
      "\n",
      "\n",
      "Example invocation:\n",
      "\tsentences: [\"This is an example sentence\" \"Each sentence is converted\"]\n",
      "\touput #0: [2][28]float32{\n",
      " {-5.6430, -6.0157, -5.8392, ..., -5.7518, -6.8059, 3.3100}},\n",
      " {-5.7150, -5.9993, -5.7604, ..., -5.7850, -6.3915, 3.4068}}\n"
     ]
    }
   ],
   "source": [
    "%%\n",
    "fmt.Printf(\"\\touput #0: %s\\n\", onnxTest(robertaID, true)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43cbede-7ace-4eb2-b2f8-f3995e7c1f8c",
   "metadata": {},
   "source": [
    "### Parse ONNX model for several repos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "976b10d2-2793-4aef-830d-d21bddb22603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sentence-transformers/all-MiniLM-L6-v2:\n",
      "\tInputs: [\"input_ids\" \"attention_mask\" \"token_type_ids\"]\n",
      "\tOutput #0: last_hidden_state - (Float32) [batch_size, sequence_length, 384]\n",
      "\tEmbeddings:\t[2][7][384]float32{\n",
      " {{0.0366, -0.0162, 0.1682, ..., 0.0554, -0.1644, -0.2967},\n",
      "  {0.7239, 0.6399, 0.1888, ..., 0.5946, 0.6206, 0.4897},\n",
      "  {0.0064, 0.0203, 0.0448, ..., 0.3464, 1.3170, -0.1670},\n",
      "  ...,\n",
      "  {0.1479, -0.0643, 0.1457, ..., 0.8837, -0.3316, 0.2975},\n",
      "  {0.5212, 0.6563, 0.5607, ..., -0.0399, 0.0412, -1.4036},\n",
      "  {1.0824, 0.7140, 0.3986, ..., -0.2301, 0.3243, -1.0313}},\n",
      " {{0.2802, 0.1165, -0.0418, ..., 0.2711, -0.1685, -0.2961},\n",
      "  {0.8729, 0.4545, -0.1091, ..., 0.1365, 0.4580, -0.2042},\n",
      "  {0.4752, 0.5731, 0.6304, ..., 0.6526, 0.5612, -1.3268},\n",
      "  ...,\n",
      "  {0.6113, 0.7920, -0.4685, ..., 0.0854, 1.0592, -0.2983},\n",
      "  {0.4115, 1.0946, 0.2385, ..., 0.8984, 0.3684, -0.7333},\n",
      "  {0.1374, 0.5555, 0.2678, ..., 0.5426, 0.4665, -0.5284}}}\n",
      "\n",
      "protectai/deberta-v3-base-zeroshot-v1-onnx:\n",
      "\tInputs: [\"input_ids\" \"attention_mask\"]\n",
      "\tOutput #0: logits - (Float32) [batch_size, 2]\n",
      "\tEmbeddings:\t[2][2]float32{\n",
      " {-3.5751, 3.4023}},\n",
      " {-2.9113, 2.9394}}\n",
      "\n",
      "KnightsAnalytics/distilbert-base-uncased-finetuned-sst-2-english:\n",
      "\tInputs: [\"input_ids\" \"attention_mask\"]\n",
      "\tOutput #0: logits - (Float32) [batch_size, 2]\n",
      "\tEmbeddings:\t[2][2]float32{\n",
      " {-1.8679, 1.7647}},\n",
      " {1.4955, -1.3462}}\n",
      "\n",
      "KnightsAnalytics/distilbert-NER:\n",
      "\tInputs: [\"input_ids\" \"attention_mask\"]\n",
      "\tOutput #0: logits - (Float32) [batch_size, sequence_length, 9]\n",
      "\tEmbeddings:\t[2][7][9]float32{\n",
      " {{7.0331, -0.1794, -1.5561, ..., -1.3033, -0.4322, -1.5858},\n",
      "  {8.2202, -0.4533, -1.9596, ..., -2.0179, -0.4971, -1.8319},\n",
      "  {9.3073, -0.4040, -1.7569, ..., -1.7475, -1.4538, -1.5460},\n",
      "  ...,\n",
      "  {9.4321, -0.6450, -1.7683, ..., -1.6711, -0.9610, -1.6652},\n",
      "  {9.0240, -0.6443, -1.4341, ..., -1.3899, -1.6808, -1.2467},\n",
      "  {6.7673, 0.3862, -1.6108, ..., -1.2095, -0.3476, -0.5290}},\n",
      " {{7.0376, -1.0962, -2.4071, ..., -1.6919, 0.8237, -1.2293},\n",
      "  {1.0937, -1.3129, -1.7949, ..., -2.5516, 7.2302, -0.2294},\n",
      "  {8.5414, -1.7554, -1.9821, ..., -1.8467, 0.0536, -0.5844},\n",
      "  ...,\n",
      "  {8.7302, -0.7292, -1.7514, ..., -1.7240, -1.7068, -0.7294},\n",
      "  {5.5813, -0.1505, -1.5533, ..., -1.2480, 1.1509, 0.5053},\n",
      "  {5.0303, 1.4254, -2.7975, ..., -3.3346, 1.7287, -1.5107}}}\n",
      "\n",
      "SamLowe/roberta-base-go_emotions-onnx:\n",
      "\tInputs: [\"input_ids\" \"attention_mask\"]\n",
      "\tOutput #0: logits - (Float32) [batch_size, 28]\n",
      "\tEmbeddings:\t[2][28]float32{\n",
      " {-5.6430, -6.0157, -5.8392, ..., -5.7518, -6.8059, 3.3100}},\n",
      " {-5.7150, -5.9993, -5.7604, ..., -5.7850, -6.3915, 3.4068}}\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "\t\"github.com/gomlx/go-huggingface/hub\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    modelIDs = []string {\n",
    "        \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        \"protectai/deberta-v3-base-zeroshot-v1-onnx\",\n",
    "        \"KnightsAnalytics/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "        \"KnightsAnalytics/distilbert-NER\",\n",
    "        \"SamLowe/roberta-base-go_emotions-onnx\",\n",
    "    }\n",
    "    hfAuthToken = os.Getenv(\"HF_TOKEN\")\n",
    "\n",
    "    sentences = []string{\n",
    "        \"This is an example sentence\", \n",
    "        \"Each sentence is converted\"}\n",
    ")\n",
    "\n",
    "%%\n",
    "for _, modelID := range modelIDs {\n",
    "    fmt.Printf(\"\\n%s:\\n\", modelID)\n",
    "    repo := hub.New(modelID).WithAuth(hfAuthToken)\n",
    "    must.M(repo.DownloadInfo(false))  // Not needed, but reports an error if repo info could not be downloaded.\n",
    "    modelFileName := \"model.onnx\"\n",
    "    if !repo.HasFile(modelFileName) { \n",
    "        modelFileName = \"onnx/model.onnx\"\n",
    "        if !repo.HasFile(modelFileName) { \n",
    "            log.Printf(\"Could not find \\\"model.onnx\\\" for repo %q\", repo)\n",
    "        }\n",
    "    }\n",
    "    modelPath := must.M1(repo.DownloadFile(modelFileName))\n",
    "    model := must.M1(onnx.ReadFile(modelPath))\n",
    "    inputNames, _ := model.Inputs()\n",
    "    fmt.Printf(\"\\tInputs: %q\\n\", inputNames)\n",
    "    outputNames, outputShapes := model.Outputs()\n",
    "    for ii, n := range outputNames {\n",
    "        fmt.Printf(\"\\tOutput #%d: %s - %s\\n\", ii, n, outputShapes[ii])\n",
    "    }\n",
    "\n",
    "    // Convert ONNX variables to GoMLX context (which stores variables):\n",
    "    ctx := context.New()\n",
    "    must.M(model.VariablesToContext(ctx))\n",
    "\n",
    "    // TODO: use github.com/gomlx/go-huggingface to tokenize according to the model.\n",
    "    inputIDs := [][]int64{\n",
    "        {101, 2023, 2003, 2019, 2742, 6251,  102},\n",
    "        { 101, 2169, 6251, 2003, 4991,  102,    0}}\n",
    "    tokenTypeIDs := [][]int64{\n",
    "        {0, 0, 0, 0, 0, 0, 0},\n",
    "        {0, 0, 0, 0, 0, 0, 0}}\n",
    "    attentionMask := [][]int64{\n",
    "        {1, 1, 1, 1, 1, 1, 1},\n",
    "        {1, 1, 1, 1, 1, 1, 0}}\n",
    "\n",
    "    \n",
    "    embeddings := context.ExecOnce(\n",
    "        backend, ctx, \n",
    "        func (ctx *context.Context, inputs []*Node) *Node {\n",
    "            inputsMap := map[string]*Node{\n",
    "                \"input_ids\": inputs[0],\n",
    "                \"attention_mask\": inputs[1]}\n",
    "            if len(inputNames) == 3 {\n",
    "                inputsMap[\"token_type_ids\"] = inputs[2]\n",
    "            }\n",
    "            modelOutputs := model.CallGraph(ctx, inputs[0].Graph(), inputsMap)\n",
    "            return modelOutputs[0]\n",
    "        }, inputIDs, attentionMask, tokenTypeIDs)    \n",
    "    fmt.Printf(\"\\tEmbeddings:\\t%s\\n\", embeddings)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.23.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
